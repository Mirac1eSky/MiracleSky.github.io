<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/M-apple.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/M-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/M-16x16.png"><link rel="mask-icon" href="/images/M.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"miraclesky.cn",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!0},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="[Deep Learning] 深层神经网络本周目标：  将深层神经网络视为一个接一个的连续块  建立和训练深层L层神经网络  分析矩阵和向量维数以检查神经网络的实现。  了解如何使用缓存将信息从正向传播传递到反向传播。  了解超参数在深度学习中的作用"><meta property="og:type" content="article"><meta property="og:title" content="neural-networks-deep-learning-week4"><meta property="og:url" content="https://miraclesky.cn/posts/d78210a7.html"><meta property="og:site_name" content="醉后凉风起，吹人舞袖回"><meta property="og:description" content="[Deep Learning] 深层神经网络本周目标：  将深层神经网络视为一个接一个的连续块  建立和训练深层L层神经网络  分析矩阵和向量维数以检查神经网络的实现。  了解如何使用缓存将信息从正向传播传递到反向传播。  了解超参数在深度学习中的作用"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/04/06/I8hkFCdOqEYH1bm.jpg"><meta property="og:image" content="https://i.loli.net/2020/04/06/74IfwvqOrUk5Wb2.png"><meta property="article:published_time" content="2020-04-03T02:04:05.000Z"><meta property="article:modified_time" content="2020-04-06T02:04:05.000Z"><meta property="article:author" content="Miracle"><meta property="article:tag" content="人工智能"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2020/04/06/I8hkFCdOqEYH1bm.jpg"><link rel="canonical" href="https://miraclesky.cn/posts/d78210a7.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>neural-networks-deep-learning-week4 | 醉后凉风起，吹人舞袖回</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="醉后凉风起，吹人舞袖回" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">醉后凉风起，吹人舞袖回</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">唯见月寒日暖</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i> 公益 404</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div> <a href="https://github.com/Mirac1eSky" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="external nofollow noopener noreferrer" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"/></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://miraclesky.cn/posts/d78210a7.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/my.jpg"><meta itemprop="name" content="Miracle"><meta itemprop="description" content="也无风雨也无晴"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="醉后凉风起，吹人舞袖回"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> neural-networks-deep-learning-week4</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-04-03 10:04:05" itemprop="dateCreated datePublished" datetime="2020-04-03T10:04:05+08:00">2020-04-03</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-04-06 10:04:05" itemprop="dateModified" datetime="2020-04-06T10:04:05+08:00">2020-04-06</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>1.7k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><script type="text/javascript" src="/js/360.js"></script><script type="text/javascript" src="/js/baidu.js"></script><h1 id="Deep-Learning-深层神经网络"><a href="#Deep-Learning-深层神经网络" class="headerlink" title="[Deep Learning] 深层神经网络"></a>[Deep Learning] 深层神经网络</h1><p>本周目标：</p><ul><li><p>将深层神经网络视为一个接一个的连续块</p></li><li><p>建立和训练深层L层神经网络</p></li><li><p>分析矩阵和向量维数以检查神经网络的实现。</p></li><li><p>了解如何使用缓存将信息从正向传播传递到反向传播。</p></li><li><p>了解超参数在深度学习中的作用</p><a id="more"></a></li></ul><hr><h1 id="块的思想"><a href="#块的思想" class="headerlink" title="块的思想"></a>块的思想</h1><ul><li>对于每层的计算，可以将其视为一个块，如下图</li></ul><p> <img src="https://i.loli.net/2020/04/06/I8hkFCdOqEYH1bm.jpg" alt></p><p> 对于此图，只需要理解其过程即可，在前向传播过程中，将变量Z1,Z2等等存储起来，然后在反向传播过程中，就可以很方便地使用他们。</p><h1 id="检查矩阵维度"><a href="#检查矩阵维度" class="headerlink" title="检查矩阵维度"></a>检查矩阵维度</h1><ul><li><p>在写代码过程中，检查各个参数的维度，能有效的避免一些奇怪的BUG。用下图举个栗子</p><p><img src="https://i.loli.net/2020/04/06/74IfwvqOrUk5Wb2.png" style="zoom:50%"></p><p>如图所示，这是一个五层的神经网络，有参数<script type="math/tex">W^{[1]},b^{[1]}...</script> 首先，先确定<script type="math/tex">W^{[1]}</script>的维度，可以看到，第一个隐藏层有三个单元，即<script type="math/tex">n^{[1]} = 3</script> ,而输入为<script type="math/tex">x_1,x_2</script>，即<script type="math/tex">n^{[0]}=n_x=2</script>,可以看做是一个 <strong>2 x 1</strong>的列向量。又有<script type="math/tex">z^{[1]} = W^{[1]}x + b^{[1]}</script>,先忽略<script type="math/tex">b^{[1]}</script>，我们已经知道<script type="math/tex">z^{[1]}</script>是 <strong>3 x 1</strong> 的列向量，那么根据线性代数的有关知识，可以直接推断出<script type="math/tex">W^{[1]}</script>是 <strong>3 x 2</strong> 的矩阵。<strong>（若有 A矩阵 的维度为 m x k ,B矩阵的维度为 k x n,那么 AB矩阵相乘得到的矩阵C的维度为 m x n）</strong>。那<script type="math/tex">b^{[1]}</script>的矩阵维度为 <strong>3 x 1</strong>。同理，我们可以推断出<script type="math/tex">W^{[2]}</script>的维度为 <strong>4 x 3</strong>，<script type="math/tex">b^{[2]}</script> 的维度为 <strong>4 x 1</strong> …..</p><p>由此，可以归纳出一个维度公式，即对于第k层中<strong>(k&gt;0）</strong>，有</p><script type="math/tex;mode=display">
\begin{array}\\
W^{[k]}的维度 = n^{[k]} * n^{[k-1]} \\
b^{[k]}的维度 = n^{[k]} * 1
\end{array}</script><p>得到每个参数的维度后，就可以很方便的检验运算是否正确咯。</p></li></ul><h1 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h1><ul><li><h2 id="什么是超参数"><a href="#什么是超参数" class="headerlink" title="什么是超参数"></a>什么是超参数</h2><ul><li>在整个NN中，有许多参数，比如<script type="math/tex">W^{[1]},b^{[1]},W^{[2]},b^{[2]}</script>等等，还有一些其他参数，比如<script type="math/tex">学习率\alpha，迭代次数\#iterations,隐藏层数L，隐藏单元个数n^{[l]},激活函数等等</script>。 而这些这参数都会影响到最终的W,b的结果，所以这些参数就被称作超参数。实际上还有很多超参数，具体的会在之后详细谈及。</li></ul></li><li><h2 id="超参数的作用"><a href="#超参数的作用" class="headerlink" title="超参数的作用"></a>超参数的作用</h2><ul><li><p>在深度学习算法中的超参数如何取值是一个以实验为依据的过程，有时候，可能依赖直觉，比如设置<script type="math/tex">\alpha = 0.01</script>,然后实际操作了一下，得到了某个结果，但是对这个结果不满意，于是把<script type="math/tex">\alpha</script>的值增加到0.05。</p><p>大部分情况下，都很难提前知道这些超参数的最优解，所以具体的取值其实是一个基于试验的过程，在过程中发现新的最优解。</p></li></ul></li></ul><h1 id="多层NN反向传播"><a href="#多层NN反向传播" class="headerlink" title="多层NN反向传播"></a>多层NN反向传播</h1><ul><li><p>在这里，我们具体讨论一下，关于多层网络的反向传播算法。对于前向传播，相信大家应该都很熟悉了，这列就不过多陈述了。主要还是反向传播（Back Propagation，简称BP）。在BP中，第一层的输入应该是在<script type="math/tex">da^{[l]}</script>,而输出是<script type="math/tex">dW^{[l]},db^{[l]}</script>。</p><p>假设一共有L层网络，Y为真实的label，则在第L层，有</p><script type="math/tex;mode=display">
\begin{array}
\\
dZ^{[L]} = A^{[L]} - Y \\
dW^{[L]} = \left(\frac{1}{m}\right) dZ^{[L]}  A^{[L-1]T} \\
db^{[L]} = \left(\frac{1}{m}\right)dZ^{[L]}
\end{array}</script></li></ul><p> 对于接下来的L-1层，有</p><script type="math/tex;mode=display">
  \begin{array}
  \\
  dZ^{[L-1]} = W^{[L]T} dZ^{[L]} * g^{[L]'}(Z^{[L-1]})  \\
  dW^{[l-1]} = \left(\frac{1}{m}\right) dZ^{[L-1]} * A^{[L-2]T} \\
  db^{[L-1]} = \left(\frac{1}{m}\right)dZ^{[L-1]}
  \end{array}</script><p> 这里公式是针对<font color="gree">所有样本</font>而言，且认为是做二元分类，即最后的<font color="gree">激活函数为sigmoid</font>。 <font color="gree">*</font> 代表 对应元素相乘，即A矩阵为 m x n, B矩阵为 m x n ，那么A * B 依旧是 m x n的矩阵。有了对应的梯度，我们就可以利用for循环来实现对L层网络的反向传播，这里要注意第一次梯度下降时要分开。</p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">------------------已经触及底线啦<i class="fa fa-paw"></i>感谢您的阅读------------------</div></div></div><div class="reward-container"><div></div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechat.jpg" alt="Miracle 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="Miracle 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> Miracle</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://miraclesky.cn/posts/d78210a7.html" title="neural-networks-deep-learning-week4">https://miraclesky.cn/posts/d78210a7.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i></span> <span class="label">RSS</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 神经网络</a></div><div class="post-widgets"><div class="wp_rating"><div id="wpac-rating"></div></div></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/49e68504.html" rel="prev" title="neural-networks-deep-learning-week3"><i class="fa fa-chevron-left"></i> neural-networks-deep-learning-week3</a></div><div class="post-nav-item"> <a href="/posts/cbb37015.html" rel="next" title="NexT升级过程中遇到的坑">NexT升级过程中遇到的坑<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80OTUwOS8yNjAwMA"></div></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Learning-深层神经网络"><span class="nav-number">1.</span> <span class="nav-text">[Deep Learning] 深层神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#块的思想"><span class="nav-number">2.</span> <span class="nav-text">块的思想</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#检查矩阵维度"><span class="nav-number">3.</span> <span class="nav-text">检查矩阵维度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#超参数"><span class="nav-number">4.</span> <span class="nav-text">超参数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是超参数"><span class="nav-number">4.1.</span> <span class="nav-text">什么是超参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#超参数的作用"><span class="nav-number">4.2.</span> <span class="nav-text">超参数的作用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多层NN反向传播"><span class="nav-number">5.</span> <span class="nav-text">多层NN反向传播</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Miracle" src="/images/my.jpg"><p class="site-author-name" itemprop="name">Miracle</p><div class="site-description" itemprop="description">也无风雨也无晴</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">6</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">5</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/Mirac1eSky" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Mirac1eSky" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="external nofollow noopener noreferrer" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Miracle</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">27k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">1:07</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>CONFIG.page.isPost&&(wpac_init=window.wpac_init||[],wpac_init.push({widget:"Rating",id:24411,el:"wpac-rating",color:"fc6423"}),function(){if(!("WIDGETPACK_LOADED"in window)){WIDGETPACK_LOADED=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//embed.widgetpack.com/widget.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t.nextSibling)}}())</script><script src="/js/local-search.js"></script><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0},react:{opacity:.7}})</script></body></html>