<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/M-apple.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/M-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/M-16x16.png"><link rel="mask-icon" href="/images/M.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"miraclesky.cn",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!0},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="[Deep Learning]将逻辑回归模型作为神经网络最近开始学习吴恩达的deeplearning课程，从第二周开始，会开始介绍关于逻辑回归模型的一些简单定义，在这里开始做一些简单的笔记，用以后面的复习。"><meta property="og:type" content="article"><meta property="og:title" content="neural-networks-deep-learning-week2"><meta property="og:url" content="https://miraclesky.cn/posts/3ee1b592.html"><meta property="og:site_name" content="You make yourself what you are"><meta property="og:description" content="[Deep Learning]将逻辑回归模型作为神经网络最近开始学习吴恩达的deeplearning课程，从第二周开始，会开始介绍关于逻辑回归模型的一些简单定义，在这里开始做一些简单的笔记，用以后面的复习。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/03/28/P8XJSrQYeNp4ozO.png"><meta property="article:published_time" content="2020-03-26T11:17:02.000Z"><meta property="article:modified_time" content="2020-03-26T11:17:02.000Z"><meta property="article:author" content="Miracle"><meta property="article:tag" content="逻辑回归"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2020/03/28/P8XJSrQYeNp4ozO.png"><link rel="canonical" href="https://miraclesky.cn/posts/3ee1b592.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>neural-networks-deep-learning-week2 | You make yourself what you are</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="You make yourself what you are" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">You make yourself what you are</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">欲上层楼 哪料山外青山楼为楼</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i> 公益 404</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div> <a href="https://github.com/Mirac1eSky" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="external nofollow noopener noreferrer" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"/></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://miraclesky.cn/posts/3ee1b592.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/my.jpg"><meta itemprop="name" content="Miracle"><meta itemprop="description" content="也无风雨也无晴"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="You make yourself what you are"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> neural-networks-deep-learning-week2</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-03-26 19:17:02" itemprop="dateCreated datePublished" datetime="2020-03-26T19:17:02+08:00">2020-03-26</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>1.5k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="Deep-Learning-将逻辑回归模型作为神经网络"><a href="#Deep-Learning-将逻辑回归模型作为神经网络" class="headerlink" title="[Deep Learning]将逻辑回归模型作为神经网络"></a>[Deep Learning]将逻辑回归模型作为神经网络</h1><p>最近开始学习吴恩达的deeplearning课程，从第二周开始，会开始介绍关于逻辑回归模型的一些简单定义，在这里开始做一些简单的笔记，用以后面的复习。</p><a id="more"></a><ul><li><h4 id="预测输出"><a href="#预测输出" class="headerlink" title="预测输出"></a>预测输出</h4></li></ul><script type="math/tex;mode=display">
  \hat{y} = sigmoid(w^{T} + b)</script><script type="math/tex;mode=display">
  sigmoid = \frac{1}{1 + e^{-z}}</script><ul><li><h4 id="损失函数（Loss）："><a href="#损失函数（Loss）：" class="headerlink" title="损失函数（Loss）："></a>损失函数（Loss）：</h4><p>对于线性回归中：</p><script type="math/tex;mode=display">
L = \left(\dfrac{1}{2}\right) (\hat{y} - y)^{2}</script><p>而在逻辑回归中，损失函数被定义为：</p><script type="math/tex;mode=display">
L = -(ylog(\hat{y}) + (1-y)log(1-\hat{y}))</script><p>具体而言，可以这么理解 yhat：</p><p>即在给定x的情况下 y等于1的概率为多少</p><script type="math/tex;mode=display">
\hat{y} = p(y=1|x)</script></li></ul><p> 也就是说</p><p> 如果 y=1</p><script type="math/tex;mode=display">
  p(y|x) = \hat{y}</script><p> 如果 y=0</p><script type="math/tex;mode=display">
  p(y|x) = 1 - \hat{y}</script><p> 将两种情况写在一起 即为 （将y=0 y=1 代入 可以得到与上面相同的公式）</p><script type="math/tex;mode=display">
  p(y|x) = \hat{y}^{y}(1 - \hat{y})^{1 - y}</script><p> 又由于log函数为单调增函数，故取对数</p><script type="math/tex;mode=display">
  log\left(p(y|x)\right) = ylog(\hat{y}) + (1-y)log(1-\hat{y}) = -L</script><p> 注意这里的负号，因为在逻辑回归中，我们想最大化概率，所以就需要最小化损失函数。</p><ul><li><h4 id="代价函数（COST）"><a href="#代价函数（COST）" class="headerlink" title="代价函数（COST）"></a>代价函数（COST）</h4><p>在m个样本中的代价可以定义为</p><script type="math/tex;mode=display">
log(p) = log\prod_{i=1}^m p(y^\left(i\right)|x^\left(i\right)) = \sum_{i=1}^m log\left(p(y^\left(i\right)|x^\left(i\right))\right) = -\sum_{i=1}^m L(\hat{y}^\left(i\right),y^\left(i\right))</script><p>（在统计学中，有一种最大似然估计的方法，即选择使式子最大化的参数。）</p><p>则有</p><script type="math/tex;mode=display">
J(w,b) =\frac{1}{m}\sum_{i=1}^m  L(\hat{y}^\left(i\right),y^\left(i\right))</script><p>因为这里要求最小值，故不需要这个负号(1/m 为缩放系数，只是为了最后的数值能在更好的尺度上，没有其他特殊含义)</p></li></ul><ul><li><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>在逻辑回归中，我们有以下的定义：</p><p><img src="https://i.loli.net/2020/03/28/P8XJSrQYeNp4ozO.png" alt></p><p>对其求偏导数（链式求导，如果不熟悉，可以看宇哥的十八讲~）</p><script type="math/tex;mode=display">
\frac{dL}{da} = -\frac{y}{a} + \frac{1-y}{1-a}</script></li></ul><script type="math/tex;mode=display">
  \frac{da}{dz} =-(1+e^{-z})^{-2} * -e^{-z} = e^{-z}*(1+e^{-z})^{-2} = a*(1-a)</script><p>注：</p><script type="math/tex;mode=display">
e^{-z}*(1+e^{-z})^{-2} = \frac{e^{-z}}{(1+e^{-z})^{2}} = \frac{1+e^{-z}-1}{(1+e^{-z})^{2}} = \frac{1}{1+e^{-z}} - \frac{1}{(1+e^{-z})^{2}} = a-a^2=a(1-a)</script><p>则有</p><script type="math/tex;mode=display">
\frac{dL}{dz} = \frac{dL}{da} * \frac{da}{dz} =(-\frac{y}{a} + \frac{1-y}{1-a}) * a(1-a)=a-y</script><p>同样的</p><script type="math/tex;mode=display">
\frac{dL}{dw_1} = x_1*dz</script><p>在计算出这些导数后，就可以进行梯度下降了</p><script type="math/tex;mode=display">
w_1 = w_1 - \alpha*dw_1</script><script type="math/tex;mode=display">
w_2 = w_2 - \alpha*dw_2</script><script type="math/tex;mode=display">
b = b -\alpha*db</script><hr><p>以上就是对第二周的小小整理（没有对向量化的部分以及numpy的使用做总结，关于numpy的使用会单独写），具体来说，这门课和之前的机器学习中讲的略有不同，比如记号之类的地方，但是大体而言还是差不多的，加油加油！</p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">------------------已经触及底线啦<i class="fa fa-paw"></i>感谢您的阅读------------------</div></div></div><div class="reward-container"><div></div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechat.jpg" alt="Miracle 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="Miracle 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> Miracle</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://miraclesky.cn/posts/3ee1b592.html" title="neural-networks-deep-learning-week2">https://miraclesky.cn/posts/3ee1b592.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i></span> <span class="label">RSS</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag"><i class="fa fa-tag"></i> 逻辑回归</a></div><div class="post-widgets"><div class="wp_rating"><div id="wpac-rating"></div></div></div><div class="post-nav"><div class="post-nav-item"></div><div class="post-nav-item"> <a href="/posts/49e68504.html" rel="next" title="neural-networks-deep-learning-week3">neural-networks-deep-learning-week3<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80OTUwOS8yNjAwMA"></div></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Learning-将逻辑回归模型作为神经网络"><span class="nav-number">1.</span> <span class="nav-text">[Deep Learning]将逻辑回归模型作为神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#预测输出"><span class="nav-number">1.0.0.1.</span> <span class="nav-text">预测输出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数（Loss）："><span class="nav-number">1.0.0.2.</span> <span class="nav-text">损失函数（Loss）：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代价函数（COST）"><span class="nav-number">1.0.0.3.</span> <span class="nav-text">代价函数（COST）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#梯度下降"><span class="nav-number">1.0.0.4.</span> <span class="nav-text">梯度下降</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Miracle" src="/images/my.jpg"><p class="site-author-name" itemprop="name">Miracle</p><div class="site-description" itemprop="description">也无风雨也无晴</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">11</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/Mirac1eSky" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Mirac1eSky" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="external nofollow noopener noreferrer" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2021</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Miracle</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">74k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">3:06</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:inline-flex"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script>CONFIG.page.isPost&&(wpac_init=window.wpac_init||[],wpac_init.push({widget:"Rating",id:24411,el:"wpac-rating",color:"fc6423"}),function(){if(!("WIDGETPACK_LOADED"in window)){WIDGETPACK_LOADED=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//embed.widgetpack.com/widget.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t.nextSibling)}}())</script><script src="/js/local-search.js"></script><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0},react:{opacity:.7}})</script></body></html>