<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>股票量化交易系统</title>
      <link href="/posts/be675351.html"/>
      <url>/posts/be675351.html</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">  <script id="hbeData" type="hbeData" data-hmacdigest="9459c183d4c30471f1861b41b3b974931c8f4f326657032130477a3669ffb78a">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好, 这里需要密码.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 股票 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微信小游戏入门</title>
      <link href="/posts/22d08c9b.html"/>
      <url>/posts/22d08c9b.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="微信小游戏开发入门"><a href="#微信小游戏开发入门" class="headerlink" title="微信小游戏开发入门"></a>微信小游戏开发入门</h1><p>之前学习了微信小程序开发，现在准备换换口味，尝试一下小游戏开发。开发环境和工具基本是不用换的，只不过我会尝试用一下webstorm，据说很好用。（如何申请微信开发者账号，云开发等这里不做介绍）</p><p>开发准备：</p><ul><li>微信开发者工具（webstorm）</li><li>nodejs</li></ul><p>知识储备(主要)：</p><ul><li>js(ES5、ES6)</li><li>canvas</li></ul><a id="more"></a><h2 id="小游戏体系结构认识"><a href="#小游戏体系结构认识" class="headerlink" title="小游戏体系结构认识"></a>小游戏体系结构认识</h2><h3 id="模块分解"><a href="#模块分解" class="headerlink" title="模块分解"></a>模块分解</h3><ul><li>game.js 游戏全局入口，是必须要有的文件</li><li>main.js  程序主类，主要用来初始化canvas和一些全局对象，各个精灵和帮绑定事件</li><li>director.js 程序导演类，用来控制游戏逻辑和精灵的创建销毁，控制游戏主循环</li><li>dataStore.js 存储游戏需要长期保存的变量和需要定时销毁的变量</li><li>resources.js 游戏资源</li><li>resourceLoader.js 资源加载，保证游戏是在加载图片结束后开始主循环</li><li>spirit.js 游戏精灵的基类，背景，陆地，小鸟等等都是它的子类</li><li>backGround.js 背景类，用来放幕布</li></ul><h3 id="内容实现"><a href="#内容实现" class="headerlink" title="内容实现"></a>内容实现</h3><h4 id="资源加载"><a href="#资源加载" class="headerlink" title="资源加载"></a>资源加载</h4><ol><li><p>首先实现资源类，将需要用到的资源统一加载</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> Resources = [</span><br><span class="line">    [<span class="string">'background'</span>,<span class="string">'res/background.png'</span>],</span><br><span class="line">    [<span class="string">'land'</span>,<span class="string">'res/land.png'</span>],</span><br><span class="line">    [<span class="string">'pencilUp'</span>,<span class="string">'res/pie_up.png'</span>],</span><br><span class="line">    [<span class="string">'pencilDown'</span>,<span class="string">'res/pie_down.png'</span>],</span><br><span class="line">    [<span class="string">'birds'</span>,<span class="string">'res/birds.png'</span>],</span><br><span class="line">    [<span class="string">'startButton'</span>,<span class="string">'res/start_button.png'</span>]</span><br><span class="line">];</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>然后实现资源加载类，</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;Resources&#125; <span class="keyword">from</span> <span class="string">"./Resources.js"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="class"><span class="keyword">class</span> <span class="title">ResourceLoader</span> </span>&#123;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.map = <span class="keyword">new</span> <span class="built_in">Map</span>(Resources)</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">let</span> [key,value] <span class="keyword">of</span> <span class="keyword">this</span>.map)&#123;</span><br><span class="line">            <span class="keyword">const</span> image = wx.createImage();</span><br><span class="line">            image.src = value;</span><br><span class="line">            <span class="keyword">this</span>.map.set(key, image);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    onLoaded(callback) &#123;</span><br><span class="line">        <span class="keyword">let</span> loadedCount = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">let</span> value <span class="keyword">of</span> <span class="keyword">this</span>.map.values())&#123;</span><br><span class="line">            value.onload = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">                loadedCount ++;</span><br><span class="line">                <span class="keyword">if</span> (loadedCount &gt;= <span class="keyword">this</span>.map.size)&#123;</span><br><span class="line">                    callback(<span class="keyword">this</span>.map);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> create()&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ResourceLoader();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先引用之前的资源类，并将对应的图片拷贝到对应位置。在这个类中，有一个构造函数，用来创建对应的image对象并重新赋值给map. onLoaded函数用来确保所有资源已经加载完成。callback作用回调函数。</p><h4 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h4><ol><li><p>将游戏中，需要用到的各种变量统一存储，便于管理。我们创建DataStore类.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="class"><span class="keyword">class</span> <span class="title">DataStore</span> </span>&#123;</span><br><span class="line">    ctx = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">static</span> getInstance()&#123;</span><br><span class="line">        <span class="keyword">if</span>(!DataStore.instance)&#123;</span><br><span class="line">            DataStore.instance = <span class="keyword">new</span> DataStore();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> DataStore.instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.map = <span class="keyword">new</span> <span class="built_in">Map</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    put(key,value) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">typeof</span> value === <span class="string">'function'</span>)&#123;</span><br><span class="line">            value = <span class="keyword">new</span> value();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.map.set(key,value);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">get</span>(key) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.map.get(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    destroy() &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">let</span> value <span class="keyword">of</span> <span class="keyword">this</span>.map.values())&#123;</span><br><span class="line">            value = <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先我们需要有一个创建实例的函数getInstance,并且设置为静态方法，这样使用的时候就不必new一个对象出来 <strong>(js可以new对象 您呢?</strong>)。并且我们需要单例模式，所以需要判断是否已经创建。put函数用来set内容。并且如果传递的参数为类名(也即函数名),则创建一个对象. get方法就是来取得内容.</p><p>未完待续…..</p></li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 游戏开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微信小游戏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达课后作业ImprovingDeepNeuralNetworks第3周</title>
      <link href="/posts/104ffa59.html"/>
      <url>/posts/104ffa59.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="TensorFlow-教程"><a href="#TensorFlow-教程" class="headerlink" title="TensorFlow 教程"></a>TensorFlow 教程</h1><p>Welcome to this week’s programming assignment. Until now, you’ve always used numpy to build neural networks. Now we will step you through a deep learning framework that will allow you to build neural networks more easily. Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up your machine learning development significantly. All of these frameworks also have a lot of documentation, which you should feel free to read. In this assignment, you will learn to do the following in TensorFlow:</p><ul><li>Initialize variables</li><li>Start your own session</li><li>Train algorithms</li><li>Implement a Neural Network</li></ul><p>Programing frameworks can not only shorten your coding time, but sometimes also perform optimizations that speed up your code</p><a id="more"></a><h2 id="Updates"><a href="#Updates" class="headerlink" title="Updates"></a><font color="darkblue">Updates</font></h2><h4 id="If-you-were-working-on-the-notebook-before-this-update…"><a href="#If-you-were-working-on-the-notebook-before-this-update…" class="headerlink" title="If you were working on the notebook before this update…"></a>If you were working on the notebook before this update…</h4><ul><li>The current notebook is version “v3b”.</li><li>You can find your original work saved in the notebook with the previous version name (it may be either TensorFlow Tutorial version 3” or “TensorFlow Tutorial version 3a.) </li><li>To view the file directory, click on the “Coursera” icon in the top left of this notebook.</li></ul><h4 id="List-of-updates"><a href="#List-of-updates" class="headerlink" title="List of updates"></a>List of updates</h4><ul><li>forward_propagation instruction now says ‘A1’ instead of ‘a1’ in the formula for Z2;<br>and are updated to say ‘A2’ instead of ‘Z2’ in the formula for Z3.</li><li>create_placeholders instruction refer to the data type “tf.float32” instead of float.</li><li>in the model function, the x axis of the plot now says “iterations (per fives)” instead of iterations(per tens)</li><li>In the linear_function, comments remind students to create the variables in the order suggested by the starter code.  The comments are updated to reflect this order.</li><li>The test of the cost function now creates the logits without passing them through a sigmoid function (since the cost function will include the sigmoid in the built-in tensorflow function).</li><li>In the ‘model’ function, the minibatch_cost is now divided by minibatch_size (instead of num_minibatches).</li><li>Updated print statements and ‘expected output that are used to check functions, for easier visual comparison.</li></ul><h2 id="1-Exploring-the-Tensorflow-Library"><a href="#1-Exploring-the-Tensorflow-Library" class="headerlink" title="1 - Exploring the Tensorflow Library"></a>1 - Exploring the Tensorflow Library</h2><p>To start, you will import the library:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line"><span class="keyword">from</span> tf_utils <span class="keyword">import</span> load_dataset, random_mini_batches, convert_to_one_hot, predict</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Now that you have imported the library, we will walk you through its different applications. You will start with an example, where we compute for you the loss of one training example. </p><script type="math/tex; mode=display">loss = \mathcal{L}(\hat{y}, y) = (\hat y^{(i)} - y^{(i)})^2 \tag{1}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">y_hat = tf.constant(<span class="number">36</span>, name=<span class="string">'y_hat'</span>)            <span class="comment"># Define y_hat constant. Set to 36.</span></span><br><span class="line">y = tf.constant(<span class="number">39</span>, name=<span class="string">'y'</span>)                    <span class="comment"># Define y. Set to 39</span></span><br><span class="line"></span><br><span class="line">loss = tf.Variable((y - y_hat)**<span class="number">2</span>, name=<span class="string">'loss'</span>)  <span class="comment"># Create a variable for the loss</span></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()         <span class="comment"># When init is run later (session.run(init)),</span></span><br><span class="line">                                                 <span class="comment"># the loss variable will be initialized and ready to be computed</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:                    <span class="comment"># Create a session and print the output</span></span><br><span class="line">    session.run(init)                            <span class="comment"># Initializes the variables</span></span><br><span class="line">    print(session.run(loss))                     <span class="comment"># Prints the loss</span></span><br></pre></td></tr></table></figure><pre><code>9</code></pre><p>Writing and running programs in TensorFlow has the following steps:</p><ol><li>Create Tensors (variables) that are not yet executed/evaluated. </li><li>Write operations between those Tensors.</li><li>Initialize your Tensors. </li><li>Create a Session. </li><li>Run the Session. This will run the operations you’d written above. </li></ol><p>Therefore, when we created a variable for the loss, we simply defined the loss as a function of other quantities, but did not evaluate its value. To evaluate it, we had to run <code>init=tf.global_variables_initializer()</code>. That initialized the loss variable, and in the last line we were finally able to evaluate the value of <code>loss</code> and print its value.</p><p>Now let us look at an easy example. Run the cell below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">2</span>)</span><br><span class="line">b = tf.constant(<span class="number">10</span>)</span><br><span class="line">c = tf.multiply(a,b)</span><br><span class="line">print(c)</span><br></pre></td></tr></table></figure><pre><code>Tensor(&quot;Mul:0&quot;, shape=(), dtype=int32)</code></pre><p>As expected, you will not see 20! You got a tensor saying that the result is a tensor that does not have the shape attribute, and is of type “int32”. All you did was put in the ‘computation graph’, but you have not run this computation yet. In order to actually multiply the two numbers, you will have to create a session and run it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure><pre><code>20</code></pre><p>Great! To summarize, <strong>remember to initialize your variables, create a session and run the operations inside the session</strong>. </p><p>Next, you’ll also have to know about placeholders. A placeholder is an object whose value you can specify only later.<br>To specify values for a placeholder, you can pass in values by using a “feed dictionary” (<code>feed_dict</code> variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the value of x in the feed_dict</span></span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.int64, name = <span class="string">'x'</span>)</span><br><span class="line">print(sess.run(<span class="number">2</span> * x, feed_dict = &#123;x: <span class="number">3</span>&#125;))</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><pre><code>6</code></pre><p>When you first defined <code>x</code> you did not have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you <strong>feed data</strong> to these placeholders when running the session. </p><p>Here’s what’s happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph.</p><h3 id="1-1-Linear-function"><a href="#1-1-Linear-function" class="headerlink" title="1.1 - Linear function"></a>1.1 - Linear function</h3><p>Lets start this programming exercise by computing the following equation: $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector. </p><p><strong>Exercise</strong>: Compute $WX + b$ where $W, X$, and $b$ are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). As an example, here is how you would define a constant X that has shape (3,1):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = tf.constant(np.random.randn(<span class="number">3</span>,<span class="number">1</span>), name = <span class="string">"X"</span>)</span><br></pre></td></tr></table></figure><br>You might find the following functions helpful: </p><ul><li>tf.matmul(…, …) to do a matrix multiplication</li><li>tf.add(…, …) to do an addition</li><li>np.random.randn(…) to initialize randomly</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_function</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_function</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a linear function: </span></span><br><span class="line"><span class="string">            Initializes X to be a random tensor of shape (3,1)</span></span><br><span class="line"><span class="string">            Initializes W to be a random tensor of shape (4,3)</span></span><br><span class="line"><span class="string">            Initializes b to be a random tensor of shape (4,1)</span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    result -- runs the session for Y = WX + b </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Note, to ensure that the "random" numbers generated match the expected results,</span></span><br><span class="line"><span class="string">    please create the variables in the order given in the starting code below.</span></span><br><span class="line"><span class="string">    (Do not re-arrange the order).</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (4 lines of code)</span></span><br><span class="line">    X = tf.constant(np.random.randn(<span class="number">3</span>,<span class="number">1</span>), name = <span class="string">"X"</span>)</span><br><span class="line">    W = tf.constant(np.random.randn(<span class="number">4</span>,<span class="number">3</span>), name = <span class="string">"W"</span>)</span><br><span class="line">    b = tf.constant(np.random.randn(<span class="number">4</span>,<span class="number">1</span>), name = <span class="string">"b"</span>)</span><br><span class="line">    Y = tf.constant(np.random.randn(<span class="number">4</span>,<span class="number">1</span>), name = <span class="string">"Y"</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    result = tf.Variable(tf.matmul(W,X) + b,name=<span class="string">'result'</span>)</span><br><span class="line">    init = tf.global_variables_initializer() </span><br><span class="line">    sess.run(init)</span><br><span class="line">    result = sess.run(result)</span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># close the session </span></span><br><span class="line">    sess.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print( <span class="string">"result = \n"</span> + str(linear_function()))</span><br></pre></td></tr></table></figure><pre><code>result = [[-2.15657382] [ 2.95891446] [-1.08926781] [-0.84538042]]</code></pre><p><strong>Expected Output </strong>: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result &#x3D; </span><br><span class="line">[[-2.15657382]</span><br><span class="line"> [ 2.95891446]</span><br><span class="line"> [-1.08926781]</span><br><span class="line"> [-0.84538042]]</span><br></pre></td></tr></table></figure><h3 id="1-2-Computing-the-sigmoid"><a href="#1-2-Computing-the-sigmoid" class="headerlink" title="1.2 - Computing the sigmoid"></a>1.2 - Computing the sigmoid</h3><p>Great! You just implemented a linear function. Tensorflow offers a variety of commonly used neural network functions like <code>tf.sigmoid</code> and <code>tf.softmax</code>. For this exercise lets compute the sigmoid function of an input. </p><p>You will do this exercise using a placeholder variable <code>x</code>. When running the session, you should use the feed dictionary to pass in the input <code>z</code>. In this exercise, you will have to (i) create a placeholder <code>x</code>, (ii) define the operations needed to compute the sigmoid using <code>tf.sigmoid</code>, and then (iii) run the session. </p><p><strong>Exercise</strong>: Implement the sigmoid function below. You should use the following: </p><ul><li><code>tf.placeholder(tf.float32, name = &quot;...&quot;)</code></li><li><code>tf.sigmoid(...)</code></li><li><code>sess.run(..., feed_dict = {x: z})</code></li></ul><p>Note that there are two typical ways to create and use sessions in tensorflow: </p><p><strong>Method 1:</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment"># Run the variables initialization (if needed), run the operations</span></span><br><span class="line">result = sess.run(..., feed_dict = &#123;...&#125;)</span><br><span class="line">sess.close() <span class="comment"># Close the session</span></span><br></pre></td></tr></table></figure><br><strong>Method 2:</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess: </span><br><span class="line">    <span class="comment"># run the variables initialization (if needed), run the operations</span></span><br><span class="line">    result = sess.run(..., feed_dict = &#123;...&#125;)</span><br><span class="line">    <span class="comment"># This takes care of closing the session for you :)</span></span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sigmoid</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the sigmoid of z</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    z -- input value, scalar or vector</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    results -- the sigmoid of z</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### ( approx. 4 lines of code)</span></span><br><span class="line">    <span class="comment"># Create a placeholder for x. Name it 'x'.</span></span><br><span class="line">    x = tf.placeholder(tf.float32, name = <span class="string">"x"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute sigmoid(x)</span></span><br><span class="line">    sigmoid = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a session, and run it. Please use the method 2 explained above. </span></span><br><span class="line">    <span class="comment"># You should use a feed_dict to pass z's value to x. </span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># Run session and call the output "result"</span></span><br><span class="line">        result = sess.run(sigmoid, feed_dict = &#123;x:z&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"sigmoid(0) = "</span> + str(sigmoid(<span class="number">0</span>)))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"sigmoid(12) = "</span> + str(sigmoid(<span class="number">12</span>)))</span><br></pre></td></tr></table></figure><pre><code>sigmoid(0) = 0.5sigmoid(12) = 0.999994</code></pre><p><strong>Expected Output </strong>: </p><table> <tr> <td>sigmoid(0)</td><td>0.5</td></tr><tr> <td>sigmoid(12)</td><td>0.999994</td></tr> </table><p><strong>To summarize, you how know how to</strong>:</p><ol><li>Create placeholders</li><li>Specify the computation graph corresponding to operations you want to compute</li><li>Create the session</li><li>Run the session, using a feed dictionary if necessary to specify placeholder variables’ values. </li></ol><h3 id="1-3-Computing-the-Cost"><a href="#1-3-Computing-the-Cost" class="headerlink" title="1.3 -  Computing the Cost"></a>1.3 -  Computing the Cost</h3><p>You can also use a built-in function to compute the cost of your neural network. So instead of needing to write code to compute this as a function of $a^{<a href="i">2</a>}$ and $y^{(i)}$ for i=1…m: </p><script type="math/tex; mode=display">J = - \frac{1}{m}  \sum_{i = 1}^m  \large ( \small y^{(i)} \log a^{ [2] (i)} + (1-y^{(i)})\log (1-a^{ [2] (i)} )\large )\small\tag{2}</script><p>you can do it in one line of code in tensorflow!</p><p><strong>Exercise</strong>: Implement the cross entropy loss. The function you will use is: </p><ul><li><code>tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)</code></li></ul><p>Your code should input <code>z</code>, compute the sigmoid (to get <code>a</code>) and then compute the cross entropy cost $J$. All this can be done using one call to <code>tf.nn.sigmoid_cross_entropy_with_logits</code>, which computes</p><script type="math/tex; mode=display">- \frac{1}{m}  \sum_{i = 1}^m  \large ( \small y^{(i)} \log \sigma(z^{[2](i)}) + (1-y^{(i)})\log (1-\sigma(z^{[2](i)})\large )\small\tag{2}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: cost</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(logits, labels)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the cost using the sigmoid cross entropy</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)</span></span><br><span class="line"><span class="string">    labels -- vector of labels y (1 or 0) </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Note: What we've been calling "z" and "y" in this class are respectively called "logits" and "labels" </span></span><br><span class="line"><span class="string">    in the TensorFlow documentation. So logits will feed into z, and labels into y. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost -- runs the session of the cost (formula (2))</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the placeholders for "logits" (z) and "labels" (y) (approx. 2 lines)</span></span><br><span class="line">    z = tf.placeholder(tf.float32, name = <span class="string">"z"</span>)</span><br><span class="line">    y = tf.placeholder(tf.float32, name = <span class="string">"y"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use the loss function (approx. 1 line)</span></span><br><span class="line">    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z,  labels = y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess = tf.Session()    </span><br><span class="line">    <span class="comment"># Run the session (approx. 1 line).</span></span><br><span class="line">    cost = sess.run(cost,feed_dict = &#123;z:logits,y:labels&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">logits = np.array([<span class="number">0.2</span>,<span class="number">0.4</span>,<span class="number">0.7</span>,<span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line">cost = cost(logits, np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"cost = "</span> + str(cost))</span><br></pre></td></tr></table></figure><pre><code>cost = [ 0.79813886  0.91301525  0.40318605  0.34115386]</code></pre><p><strong>Expected Output </strong> : </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cost &#x3D; [ 0.79813886  0.91301525  0.40318605  0.34115386]</span><br></pre></td></tr></table></figure><h3 id="1-4-Using-One-Hot-encodings"><a href="#1-4-Using-One-Hot-encodings" class="headerlink" title="1.4 - Using One Hot encodings"></a>1.4 - Using One Hot encodings</h3><p>Many times in deep learning you will have a y vector with numbers ranging from 0 to C-1, where C is the number of classes. If C is for example 4, then you might have the following y vector which you will need to convert as follows:</p><p><img src="https://i.loli.net/2020/05/06/6w45ErVRnhav1jQ.png" style="width:600px;height:150px;"></p><p>This is called a “one hot” encoding, because in the converted representation exactly one element of each column is “hot” (meaning set to 1). To do this conversion in numpy, you might have to write a few lines of code. In tensorflow, you can use one line of code: </p><ul><li>tf.one_hot(labels, depth, axis) </li></ul><p><strong>Exercise:</strong> Implement the function below to take one vector of labels and the total number of classes $C$, and return the one hot encoding. Use <code>tf.one_hot()</code> to do this. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: one_hot_matrix</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot_matrix</span><span class="params">(labels, C)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a matrix where the i-th row corresponds to the ith class number and the jth column</span></span><br><span class="line"><span class="string">                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) </span></span><br><span class="line"><span class="string">                     will be 1. </span></span><br><span class="line"><span class="string">                     </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    labels -- vector containing the labels </span></span><br><span class="line"><span class="string">    C -- number of classes, the depth of the one hot dimension</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    one_hot -- one hot matrix</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)</span></span><br><span class="line">    C = tf.constant(C, name = <span class="string">"C"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use tf.one_hot, be careful with the axis (approx. 1 line)</span></span><br><span class="line">    one_hot_matrix = tf.one_hot(labels,C,axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session (approx. 1 line)</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    <span class="comment"># Run the session (approx. 1 line)</span></span><br><span class="line">    one_hot = sess.run(one_hot_matrix)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> one_hot</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">labels = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">one_hot = one_hot_matrix(labels, C = <span class="number">4</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"one_hot = \n"</span> + str(one_hot))</span><br></pre></td></tr></table></figure><pre><code>one_hot = [[ 0.  0.  0.  1.  0.  0.] [ 1.  0.  0.  0.  0.  1.] [ 0.  1.  0.  0.  1.  0.] [ 0.  0.  1.  0.  0.  0.]]</code></pre><p><strong>Expected Output</strong>: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">one_hot &#x3D; </span><br><span class="line">[[ 0.  0.  0.  1.  0.  0.]</span><br><span class="line"> [ 1.  0.  0.  0.  0.  1.]</span><br><span class="line"> [ 0.  1.  0.  0.  1.  0.]</span><br><span class="line"> [ 0.  0.  1.  0.  0.  0.]]</span><br></pre></td></tr></table></figure><h3 id="1-5-Initialize-with-zeros-and-ones"><a href="#1-5-Initialize-with-zeros-and-ones" class="headerlink" title="1.5 - Initialize with zeros and ones"></a>1.5 - Initialize with zeros and ones</h3><p>Now you will learn how to initialize a vector of zeros and ones. The function you will be calling is <code>tf.ones()</code>. To initialize with zeros you could use tf.zeros() instead. These functions take in a shape and return an array of dimension shape full of zeros and ones respectively. </p><p><strong>Exercise:</strong> Implement the function below to take in a shape and to return an array (of the shape’s dimension of ones). </p><ul><li>tf.ones(shape)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: ones</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates an array of ones of dimension shape</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    shape -- shape of the array you want to create</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    ones -- array containing only ones</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create "ones" tensor using tf.ones(...). (approx. 1 line)</span></span><br><span class="line">    ones = tf.ones(shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session (approx. 1 line)</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the session to compute 'ones' (approx. 1 line)</span></span><br><span class="line">    ones = sess.run(ones)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> ones</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"ones = "</span> + str(ones([<span class="number">3</span>])))</span><br></pre></td></tr></table></figure><pre><code>ones = [ 1.  1.  1.]</code></pre><p><strong>Expected Output:</strong></p><table>     <tr>         <td>            ones        </td>        <td>        [ 1.  1.  1.]        </td>    </tr></table><h1 id="2-Building-your-first-neural-network-in-tensorflow"><a href="#2-Building-your-first-neural-network-in-tensorflow" class="headerlink" title="2 - Building your first neural network in tensorflow"></a>2 - Building your first neural network in tensorflow</h1><p>In this part of the assignment you will build a neural network using tensorflow. Remember that there are two parts to implement a tensorflow model:</p><ul><li>Create the computation graph</li><li>Run the graph</li></ul><p>Let’s delve into the problem you’d like to solve!</p><h3 id="2-0-Problem-statement-SIGNS-Dataset"><a href="#2-0-Problem-statement-SIGNS-Dataset" class="headerlink" title="2.0 - Problem statement: SIGNS Dataset"></a>2.0 - Problem statement: SIGNS Dataset</h3><p>One afternoon, with some friends we decided to teach our computers to decipher sign language. We spent a few hours taking pictures in front of a white wall and came up with the following dataset. It’s now your job to build an algorithm that would facilitate communications from a speech-impaired person to someone who doesn’t understand sign language.</p><ul><li><strong>Training set</strong>: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).</li><li><strong>Test set</strong>: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).</li></ul><p>Note that this is a subset of the SIGNS dataset. The complete dataset contains many more signs.</p><p>Here are examples for each number, and how an explanation of how we represent the labels. These are the original pictures, before we lowered the image resolutoion to 64 by 64 pixels.<br><img src="https://i.loli.net/2020/05/06/lzhCL2vfEMYVBbg.png" style="width:800px;height:350px;"></p><p>Run the following code to load the dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Loading the dataset</span></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br></pre></td></tr></table></figure><p>Change the index below and run the cell to visualize some examples in the dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of a picture</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line">plt.imshow(X_train_orig[index])</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(np.squeeze(Y_train_orig[:, index])))</span><br></pre></td></tr></table></figure><pre><code>y = 5</code></pre><p><img src="https://i.loli.net/2020/05/06/cuinrEUI1ygbCZ7.png" alt></p><p>As usual you flatten the image dataset, then normalize it by dividing by 255. On top of that, you will convert each label to a one-hot vector as shown in Figure 1. Run the cell below to do so.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Flatten the training and test images</span></span><br><span class="line">X_train_flatten = X_train_orig.reshape(X_train_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span><br><span class="line">X_test_flatten = X_test_orig.reshape(X_test_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_flatten/<span class="number">255.</span></span><br><span class="line">X_test = X_test_flatten/<span class="number">255.</span></span><br><span class="line"><span class="comment"># Convert training and test labels to one hot matrices</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>)</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of training examples = "</span> + str(X_train.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of test examples = "</span> + str(X_test.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_train shape: "</span> + str(X_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_train shape: "</span> + str(Y_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_test shape: "</span> + str(X_test.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_test shape: "</span> + str(Y_test.shape))</span><br></pre></td></tr></table></figure><pre><code>number of training examples = 1080number of test examples = 120X_train shape: (12288, 1080)Y_train shape: (6, 1080)X_test shape: (12288, 120)Y_test shape: (6, 120)</code></pre><p><strong>Note</strong> that 12288 comes from $64 \times 64 \times 3$. Each image is square, 64 by 64 pixels, and 3 is for the RGB colors. Please make sure all these shapes make sense to you before continuing.</p><p><strong>Your goal</strong> is to build an algorithm capable of recognizing a sign with high accuracy. To do so, you are going to build a tensorflow model that is almost the same as one you have previously built in numpy for cat recognition (but now using a softmax output). It is a great occasion to compare your numpy implementation to the tensorflow one. </p><p><strong>The model</strong> is <em>LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SOFTMAX</em>. The SIGMOID output layer has been converted to a SOFTMAX. A SOFTMAX layer generalizes SIGMOID to when there are more than two classes. </p><h3 id="2-1-Create-placeholders"><a href="#2-1-Create-placeholders" class="headerlink" title="2.1 - Create placeholders"></a>2.1 - Create placeholders</h3><p>Your first task is to create placeholders for <code>X</code> and <code>Y</code>. This will allow you to later pass your training data in when you run your session. </p><p><strong>Exercise:</strong> Implement the function below to create the placeholders in tensorflow.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: create_placeholders</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_x, n_y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates the placeholders for the tensorflow session.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)</span></span><br><span class="line"><span class="string">    n_y -- scalar, number of classes (from 0 to 5, so -&gt; 6)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- placeholder for the data input, of shape [n_x, None] and dtype "tf.float32"</span></span><br><span class="line"><span class="string">    Y -- placeholder for the input labels, of shape [n_y, None] and dtype "tf.float32"</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Tips:</span></span><br><span class="line"><span class="string">    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.</span></span><br><span class="line"><span class="string">      In fact, the number of examples during test/train is different.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">    X = tf.placeholder(tf.float32, shape=[n_x,<span class="literal">None</span>],name = <span class="string">"X"</span>)</span><br><span class="line">    Y = tf.placeholder(tf.float32, shape=[n_y,<span class="literal">None</span>],name = <span class="string">"Y"</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, Y = create_placeholders(<span class="number">12288</span>, <span class="number">6</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X = "</span> + str(X))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y = "</span> + str(Y))</span><br></pre></td></tr></table></figure><pre><code>X = Tensor(&quot;X_1:0&quot;, shape=(12288, ?), dtype=float32)Y = Tensor(&quot;Y_1:0&quot;, shape=(6, ?), dtype=float32)</code></pre><p><strong>Expected Output</strong>: </p><table>     <tr>         <td>            X        </td>        <td>        Tensor("Placeholder_1:0", shape=(12288, ?), dtype=float32) (not necessarily Placeholder_1)        </td>    </tr>    <tr>         <td>            Y        </td>        <td>        Tensor("Placeholder_2:0", shape=(6, ?), dtype=float32) (not necessarily Placeholder_2)        </td>    </tr></table><h3 id="2-2-Initializing-the-parameters"><a href="#2-2-Initializing-the-parameters" class="headerlink" title="2.2 - Initializing the parameters"></a>2.2 - Initializing the parameters</h3><p>Your second task is to initialize the parameters in tensorflow.</p><p><strong>Exercise:</strong> Implement the function below to initialize the parameters in tensorflow. You are going use Xavier Initialization for weights and Zero Initialization for biases. The shapes are given below. As an example, to help you, for W1 and b1 you could use: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W1 = tf.get_variable(<span class="string">"W1"</span>, [<span class="number">25</span>,<span class="number">12288</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">b1 = tf.get_variable(<span class="string">"b1"</span>, [<span class="number">25</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br></pre></td></tr></table></figure><p>Please use <code>seed = 1</code> to make sure your results match ours.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Initializes parameters to build a neural network with tensorflow. The shapes are:</span></span><br><span class="line"><span class="string">                        W1 : [25, 12288]</span></span><br><span class="line"><span class="string">                        b1 : [25, 1]</span></span><br><span class="line"><span class="string">                        W2 : [12, 25]</span></span><br><span class="line"><span class="string">                        b2 : [12, 1]</span></span><br><span class="line"><span class="string">                        W3 : [6, 12]</span></span><br><span class="line"><span class="string">                        b3 : [6, 1]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                   <span class="comment"># so that your "random" numbers match ours</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 6 lines of code)</span></span><br><span class="line">    W1 = tf.get_variable(<span class="string">"W1"</span>, [<span class="number">25</span>,<span class="number">12288</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b1 = tf.get_variable(<span class="string">"b1"</span>, [<span class="number">25</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    W2 = tf.get_variable(<span class="string">"W2"</span>, [<span class="number">12</span>,<span class="number">25</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b2 = tf.get_variable(<span class="string">"b2"</span>, [<span class="number">12</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    W3 = tf.get_variable(<span class="string">"W3"</span>, [<span class="number">6</span>,<span class="number">12</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b3 = tf.get_variable(<span class="string">"b3"</span>, [<span class="number">6</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2,</span><br><span class="line">                  <span class="string">"W3"</span>: W3,</span><br><span class="line">                  <span class="string">"b3"</span>: b3&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">    print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">    print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">    print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W1 &#x3D; &lt;tf.Variable &#39;W1:0&#39; shape&#x3D;(25, 12288) dtype&#x3D;float32_ref&gt;</span><br><span class="line">b1 &#x3D; &lt;tf.Variable &#39;b1:0&#39; shape&#x3D;(25, 1) dtype&#x3D;float32_ref&gt;</span><br><span class="line">W2 &#x3D; &lt;tf.Variable &#39;W2:0&#39; shape&#x3D;(12, 25) dtype&#x3D;float32_ref&gt;</span><br><span class="line">b2 &#x3D; &lt;tf.Variable &#39;b2:0&#39; shape&#x3D;(12, 1) dtype&#x3D;float32_ref&gt;</span><br></pre></td></tr></table></figure><p><strong>Expected Output</strong>: </p><table>     <tr>         <td>            W1        </td>        <td>         tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref         </td>    </tr>    <tr>         <td>            b1        </td>        <td>         tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref         </td>    </tr>    <tr>         <td>            W2        </td>        <td>        tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref         </td>    </tr>    <tr>         <td>            b2        </td>        <td>        tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref        </td>    </tr></table><p>As expected, the parameters haven’t been evaluated yet.</p><h3 id="2-3-Forward-propagation-in-tensorflow"><a href="#2-3-Forward-propagation-in-tensorflow" class="headerlink" title="2.3 - Forward propagation in tensorflow"></a>2.3 - Forward propagation in tensorflow</h3><p>You will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass. The functions you will be using are: </p><ul><li><code>tf.add(...,...)</code> to do an addition</li><li><code>tf.matmul(...,...)</code> to do a matrix multiplication</li><li><code>tf.nn.relu(...)</code> to apply the ReLU activation</li></ul><p><strong>Question:</strong> Implement the forward pass of the neural network. We commented for you the numpy equivalents so that you can compare the tensorflow implementation to numpy. It is important to note that the forward propagation stops at <code>z3</code>. The reason is that in tensorflow the last linear layer output is given as input to the function computing the loss. Therefore, you don’t need <code>a3</code>!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation for the model: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SOFTMAX</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset placeholder, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3"</span></span><br><span class="line"><span class="string">                  the shapes are given in initialize_parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z3 -- the output of the last LINEAR unit</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary "parameters" </span></span><br><span class="line">    W1 = parameters[<span class="string">'W1'</span>]</span><br><span class="line">    b1 = parameters[<span class="string">'b1'</span>]</span><br><span class="line">    W2 = parameters[<span class="string">'W2'</span>]</span><br><span class="line">    b2 = parameters[<span class="string">'b2'</span>]</span><br><span class="line">    W3 = parameters[<span class="string">'W3'</span>]</span><br><span class="line">    b3 = parameters[<span class="string">'b3'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:</span></span><br><span class="line">    <span class="comment">#Z1 = tf.add(tf.matmul(tf.cast(W1,tf.float32),tf.cast(X,tf.float32)),tf.cast(b1,tf.float32))   </span></span><br><span class="line">    Z1 =  tf.matmul(W1,X) + b1   <span class="comment"># Z1 = np.dot(W1, X) + b1</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)                                              <span class="comment"># A1 = relu(Z1)</span></span><br><span class="line">    Z2 = tf.matmul(W2,A1) + b2                                             <span class="comment"># Z2 = np.dot(W2, A1) + b2</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)                                               <span class="comment"># A2 = relu(Z2)</span></span><br><span class="line">    Z3 = tf.matmul(W3,A2) + b3                                              <span class="comment"># Z3 = np.dot(W3, A2) + b3</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    X, Y = create_placeholders(<span class="number">12288</span>, <span class="number">6</span>)</span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    print(<span class="string">"Z3 = "</span> + str(Z3))</span><br></pre></td></tr></table></figure><pre><code>Z3 = Tensor(&quot;add_1:0&quot;, shape=(6, ?), dtype=float32)</code></pre><p><strong>Expected Output</strong>: </p><table>     <tr>         <td>            Z3        </td>        <td>        Tensor("Add_2:0", shape=(6, ?), dtype=float32)        </td>    </tr></table><p>You may have noticed that the forward propagation doesn’t output any cache. You will understand why below, when we get to brackpropagation.</p><h3 id="2-4-Compute-cost"><a href="#2-4-Compute-cost" class="headerlink" title="2.4 Compute cost"></a>2.4 Compute cost</h3><p>As seen before, it is very easy to compute the cost using:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))</span><br></pre></td></tr></table></figure><br><strong>Question</strong>: Implement the cost function below. </p><ul><li>It is important to know that the “<code>logits</code>“ and “<code>labels</code>“ inputs of <code>tf.nn.softmax_cross_entropy_with_logits</code> are expected to be of shape (number of examples, num_classes). We have thus transposed Z3 and Y for you.</li><li>Besides, <code>tf.reduce_mean</code> basically does the summation over the examples.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(Z3, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector placeholder, same shape as Z3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - Tensor of the cost function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)</span></span><br><span class="line">    logits = tf.transpose(Z3)</span><br><span class="line">    labels = tf.transpose(Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line of code)</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=labels))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    X, Y = create_placeholders(<span class="number">12288</span>, <span class="number">6</span>)</span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    cost = compute_cost(Z3, Y)</span><br><span class="line">    print(<span class="string">"cost = "</span> + str(cost))</span><br></pre></td></tr></table></figure><pre><code>cost = Tensor(&quot;Mean:0&quot;, shape=(), dtype=float32)</code></pre><p><strong>Expected Output</strong>: </p><table>     <tr>         <td>            cost        </td>        <td>        Tensor("Mean:0", shape=(), dtype=float32)        </td>    </tr></table><h3 id="2-5-Backward-propagation-amp-parameter-updates"><a href="#2-5-Backward-propagation-amp-parameter-updates" class="headerlink" title="2.5 - Backward propagation &amp; parameter updates"></a>2.5 - Backward propagation &amp; parameter updates</h3><p>This is where you become grateful to programming frameworks. All the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.</p><p>After you compute the cost function. You will create an “<code>optimizer</code>“ object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.</p><p>For instance, for gradient descent the optimizer would be:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)</span><br></pre></td></tr></table></figure></p><p>To make the optimization you would do:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_ , c = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br></pre></td></tr></table></figure></p><p>This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.</p><p><strong>Note</strong> When coding, we often use <code>_</code> as a “throwaway” variable to store values that we won’t need to use later. Here, <code>_</code> takes on the evaluated value of <code>optimizer</code>, which we don’t need (and <code>c</code> takes the value of the <code>cost</code> variable). </p><h3 id="2-6-Building-the-model"><a href="#2-6-Building-the-model" class="headerlink" title="2.6 - Building the model"></a>2.6 - Building the model</h3><p>Now, you will bring it all together! </p><p><strong>Exercise:</strong> Implement the model. You will be calling the functions you had previously implemented.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, learning_rate = <span class="number">0.0001</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          num_epochs = <span class="number">1500</span>, minibatch_size = <span class="number">32</span>, print_cost = True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a three-layer tensorflow neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SOFTMAX.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)</span></span><br><span class="line"><span class="string">    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)</span></span><br><span class="line"><span class="string">    X_test -- training set, of shape (input size = 12288, number of training examples = 120)</span></span><br><span class="line"><span class="string">    Y_test -- test set, of shape (output size = 6, number of test examples = 120)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs of the optimization loop</span></span><br><span class="line"><span class="string">    minibatch_size -- size of a minibatch</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 100 epochs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep consistent results</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep consistent results</span></span><br><span class="line">    (n_x, m) = X_train.shape                          <span class="comment"># (n_x: input size, m : number of examples in the train set)</span></span><br><span class="line">    n_y = Y_train.shape[<span class="number">0</span>]                            <span class="comment"># n_y : output size</span></span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of shape (n_x, n_y)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    X, Y = create_placeholders(n_x, n_y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    Z3 = forward_propagation(X_train, parameters)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    cost = compute_cost(Z3, Y_train)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line"></span><br><span class="line">            epoch_cost = <span class="number">0.</span>                       <span class="comment"># Defines a cost related to an epoch</span></span><br><span class="line">            num_minibatches = int(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the "optimizer" and the "cost", the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br><span class="line">                <span class="comment">### END CODE HERE ###</span></span><br><span class="line">                </span><br><span class="line">                epoch_cost += minibatch_cost / minibatch_size</span><br><span class="line">            print(<span class="string">"epoch"</span>,epoch)</span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, epoch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(epoch_cost)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per fives)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># lets save the parameters in a variable</span></span><br><span class="line">        parameters = sess.run(parameters)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"Parameters have been trained!"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"Train Accuracy:"</span>, accuracy.eval(&#123;X: X_train, Y: Y_train&#125;))</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"Test Accuracy:"</span>, accuracy.eval(&#123;X: X_test, Y: Y_test&#125;))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><p>Run the following cell to train your model! On our machine it takes about 5 minutes. Your “Cost after epoch 100” should be 1.048222. If it’s not, don’t waste time; interrupt the training by clicking on the square (⬛) in the upper bar of the notebook, and try to correct your code. If it is the correct cost, take a break and come back in 5 minutes!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure><p><strong>Expected Output</strong>:</p><table>     <tr>         <td>            Train Accuracy        </td>        <td>        0.999074        </td>    </tr>    <tr>         <td>            Test Accuracy        </td>        <td>        0.716667        </td>    </tr></table><p>Amazing, your algorithm can recognize a sign representing a figure between 0 and 5 with 71.7% accuracy.</p><p><strong>Insights</strong>:</p><ul><li>Your model seems big enough to fit the training set well. However, given the difference between train and test accuracy, you could try to add L2 or dropout regularization to reduce overfitting. </li><li>Think about the session as a block of code to train the model. Each time you run the session on a minibatch, it trains the parameters. In total you have run the session a large number of times (1500 epochs) until you obtained well trained parameters.</li></ul><h3 id="2-7-Test-with-your-own-image-optional-ungraded-exercise"><a href="#2-7-Test-with-your-own-image-optional-ungraded-exercise" class="headerlink" title="2.7 - Test with your own image (optional / ungraded exercise)"></a>2.7 - Test with your own image (optional / ungraded exercise)</h3><p>Congratulations on finishing this assignment. You can now take a picture of your hand and see the output of your model. To do that:</p><pre><code>1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub.2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder3. Write your image&#39;s name in the following code4. Run the code and check if the algorithm is right!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"></span><br><span class="line"><span class="comment">## START CODE HERE ## (PUT YOUR IMAGE NAME) </span></span><br><span class="line">my_image = <span class="string">"thumbs_up.jpg"</span></span><br><span class="line"><span class="comment">## END CODE HERE ##</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We preprocess your image to fit your algorithm.</span></span><br><span class="line">fname = <span class="string">"images/"</span> + my_image</span><br><span class="line">image = np.array(ndimage.imread(fname, flatten=<span class="literal">False</span>))</span><br><span class="line">image = image/<span class="number">255.</span></span><br><span class="line">my_image = scipy.misc.imresize(image, size=(<span class="number">64</span>,<span class="number">64</span>)).reshape((<span class="number">1</span>, <span class="number">64</span>*<span class="number">64</span>*<span class="number">3</span>)).T</span><br><span class="line">my_image_prediction = predict(my_image, parameters)</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br><span class="line">print(<span class="string">"Your algorithm predicts: y = "</span> + str(np.squeeze(my_image_prediction)))</span><br></pre></td></tr></table></figure><p>You indeed deserved a “thumbs-up” although as you can see the algorithm seems to classify it incorrectly. The reason is that the training set doesn’t contain any “thumbs-up”, so the model doesn’t know how to deal with it! We call that a “mismatched data distribution” and it is one of the various of the next course on “Structuring Machine Learning Projects”.</p><p><strong>What you should remember</strong>:</p><ul><li>Tensorflow is a programming framework used in deep learning</li><li>The two main object classes in tensorflow are Tensors and Operators. </li><li>When you code in tensorflow you have to take the following steps:<ul><li>Create a graph containing Tensors (Variables, Placeholders …) and Operations (tf.matmul, tf.add, …)</li><li>Create a session</li><li>Initialize the session</li><li>Run the session to execute the graph</li></ul></li><li>You can execute the graph multiple times as you’ve seen in model()</li><li>The backpropagation and optimization is automatically done when running the session on the “optimizer” object.</li></ul>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 课后作业 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习系列第二课第二周笔记</title>
      <link href="/posts/1c0195e4.html"/>
      <url>/posts/1c0195e4.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="【吴恩达深度学习系列第二课第二周笔记】"><a href="#【吴恩达深度学习系列第二课第二周笔记】" class="headerlink" title="【吴恩达深度学习系列第二课第二周笔记】"></a>【吴恩达深度学习系列第二课第二周笔记】</h1><p><strong>关键概念</strong>：</p><ul><li>记住不同的优化方法，如(Stochastic) Gradient Descent, Momentum, RMSProp and Adam</li><li>采用随机小批量算法加快收敛速度，提高优化效果</li><li>了解学习率衰减的好处，并将其应用到优化中</li></ul><a id="more"></a><h2 id="mini-batch-gradient-descent"><a href="#mini-batch-gradient-descent" class="headerlink" title="mini-batch gradient descent"></a>mini-batch gradient descent</h2><p>之前在实现梯度下降的时候，都是对整个数据集进行循环的。现在我们采用一种新的方法，</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 方差偏差 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python安装PyUserInput的问题</title>
      <link href="/posts/7c892205.html"/>
      <url>/posts/7c892205.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><p>今天在碰到一个偏向挂机的游戏，需要点击屏幕来赚取经济。为了防止鼠标过早报废，所以就想写个脚本自动模拟点击。但是在直接安装PyUserInput的模块时，遇到了问题。</p><a id="more"></a><p>查阅资料后发现是因为安装PyUserInput之前需要安装pyHook模块。所以直接去 <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="external nofollow noopener noreferrer">这个网址</a>上搜索然后直接下载（注意：要下载与你python对应的版本，比如我的是3.5版本64位，所以就下载pyHook‑1.5.1‑cp35‑cp35m‑win_amd64.whl）。然后进入到下载目录，切换到你的虚拟环境，直接pip install。之后在在直接用 pip install PyUserInput就不会出现问题了。</p><p>然后导入模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymouse,pykeyboard,os,sys</span><br><span class="line"><span class="keyword">from</span> pymouse <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pykeyboard <span class="keyword">import</span> PyKeyboard</span><br></pre></td></tr></table></figure><p>实例化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m = PyMouse() </span><br><span class="line">k = PyKeyboard()</span><br></pre></td></tr></table></figure><p>最后模拟点击屏幕：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">m.click(x,y,button,n) </span><br><span class="line"><span class="comment">#鼠标点击 x,y –是坐标位置 </span></span><br><span class="line"><span class="comment">#buttong –1表示左键，2表示点击右键 </span></span><br><span class="line"><span class="comment">#n –点击次数，默认是1次，2表示双击</span></span><br></pre></td></tr></table></figure><p>最后在线程写个循环就可以了。</p>]]></content>
      
      
      <categories>
          
          <category> pip安装失败 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyUserInput </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习系列第二课第一周笔记</title>
      <link href="/posts/1ca99e0.html"/>
      <url>/posts/1ca99e0.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="【吴恩达深度学习系列第二课第一周笔记】"><a href="#【吴恩达深度学习系列第二课第一周笔记】" class="headerlink" title="【吴恩达深度学习系列第二课第一周笔记】"></a>【吴恩达深度学习系列第二课第一周笔记】</h1><p>现在开始记录第二课程的笔记。会慢慢更新的。</p><p><strong>关键概念</strong>：</p><ul><li><p>不同类型的初始化会导致不同的结果</p></li><li><p>认识复杂神经网络初始化的重要性</p></li><li><p>识别 train / dev / test 集之间的差异</p></li><li><p>诊断模型中的偏差和方差问题</p></li><li><p>学习何时以及如何使用规范化方法</p></li><li><p>理解深度学习中的实验问题</p></li><li><p>使用梯度检查来验证反向传播实现的正确性</p></li></ul><a id="more"></a><h2 id="正确设置训练集，验证集（开发集）测试集"><a href="#正确设置训练集，验证集（开发集）测试集" class="headerlink" title="正确设置训练集，验证集（开发集）测试集"></a>正确设置训练集，验证集（开发集）测试集</h2><p>在机器学习小数据量时代即当你的数据集在100,1000,10000的时候，可以采用60%：20%：20%的比例来，即用60%的数据来训练模型，20%的数据来评估不同你不同的模型，最后用20%的数据集来评估选定模型的性能。</p><p>但是当数量达到百万级别时，我们就可能不在需要这么高的比例来划分出验证集。因为验证集的目的就是用来快速验证不同的算法之间的差别，所以可能不再不要这么多的数据作为验证集。举个例子，当我们有一百万的数据时，可能只需要一万条数据来验证就行了。同样的，最后的测试集也是如此。所以最终的比例就是98%：1%：1%。对于数据量过百万的情况，可能就是99.5%：0.25%：0.25%.</p><h2 id="训练集和测试集分布不匹配"><a href="#训练集和测试集分布不匹配" class="headerlink" title="训练集和测试集分布不匹配"></a>训练集和测试集分布不匹配</h2><p>比如说你有个应用，通过用户上传图片，然后告诉用户这张图片是不是猫咪。相比较而言，你的训练集都是从网上下载下来的高分辨率图片，并且构图精巧。而用户上传的图片可能分辨率就不是很高，并且更加随意。这个时候你的训练集和测试集的分布就不一样了。对此，吴老师的建议是确保分布相同，具体会在后面的课程提到。</p><h2 id="偏差和方差以及偏差方差权衡"><a href="#偏差和方差以及偏差方差权衡" class="headerlink" title="偏差和方差以及偏差方差权衡"></a>偏差和方差以及偏差方差权衡</h2><p>对于偏差和方差问题应该都会有大致了解了。比如高偏差对应欠拟合，高方差对应了过拟合。如图所示：</p><p><img src="https://i.loli.net/2020/04/16/s7D4uXlU5OikgQB.png" style="zoom:50%;"></p><p>接下来看看如何分析偏差和方差：</p><p>假设你有个识别猫咪的分类器，得到了不同的误差集合：</p><p><img src="https://i.loli.net/2020/04/16/dyigBtOIGLu3nzc.png" alt></p><ol><li>当训练集误差是第一列时，可以看到在训练集上误差很小，但是在验证集上误差很大，说明过拟合了。</li><li>当训练集为第二列时，可以看到在训练集和验证集上的表现都不是很好，说明该模型在训练集是欠拟合，而在验证集上表现也符合该预测</li><li>当训练集为第三列时，训练集和验证集的表现都不行，并且验证集的表现比训练集差很多。说明该模型不仅存在高偏差的问题，并且还存在高方差的问题。也就是说该分类器在总体上是欠拟合的，但是在部分数据上又表现出过拟合的问题。</li><li>第四列则是开发人员很希望看到的，就是在训练集和验证集上的误差都很小，说明是适拟合的情况。</li></ol><h2 id="机器学习的基本方法"><a href="#机器学习的基本方法" class="headerlink" title="机器学习的基本方法"></a>机器学习的基本方法</h2><p>当训练好你的网络，首先应该看看是否存在高偏差的问题：</p><ul><li>如果存在，则尝试减少，例如使用更大的网络，训练的更久一点等等这些方法</li><li>如果不存在，则看看有没有高方差的问题。如果存在，尝试获得更多的数据，或者正则化</li></ul><p>尝试上面的方法，直到找到低偏差，低方差的网络。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="正则化的定义"><a href="#正则化的定义" class="headerlink" title="正则化的定义"></a>正则化的定义</h3><p>如果你的NN发生了高偏差，一般可以采用正则化来尝试解决问题。获取更多数据也是解决高方差问题的一个很可靠的方法 ，但你并不是总能获取到更多的训练数据 ，或者获取更多数据的代价太大 。但使用正则化通常有助于防止过拟合 并降低网络的误差。</p><h4 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h4><p>在逻辑回归中，你会尝试最小化代价函数<strong>J</strong> ，该代价函数定义为 ：每一个训练样本的预测的损失之和 其中w和b是 逻辑回归的参数 ，因此w是一个x维的参数向量 b是一个实数，要为逻辑回归正则化 你需要加上这个lambda 它称为正则化参数。正则项被定义为：</p><script type="math/tex; mode=display">\frac{\lambda}{2m}||w||^{2}_2</script><script type="math/tex; mode=display">||w||^{2}_2 =\sum_{j=1}^{n_x}w_j^2 = w^Tw</script><p>这里的<script type="math/tex">||w||^{2}_2</script>也可以叫做w的范数，也被称作L2正则化。与此同时，有另一种正则化叫做L1正则化，如下：</p><script type="math/tex; mode=display">\sum_{j=1}^{n_x}|w_j| =||w||_1</script><p>如果使用L1正则化，w最后会变得稀疏，这意味着w矢量中有很多0 。有些人认为这有助于压缩模型 ，因为有一部分参数是0 只需较少的内存来存储模型，然而在实践中发现 通过L1正则化让模型变得稀疏，带来的收效甚微 所以我觉得至少在压缩模型的目标上 它的作用不大 。在训练网络时，L2正则化使用得频繁得多。（注意：==在python中，lambda是保留关键字，所以用lambd代替==）。在上面发现，正则化参数时，并没有将b包含进来，实际上你可以这样做，但通常会把它省略掉。因为你可以看一下你的参数w往往是一个非常高维的参数矢量，尤其是在发生高方差问题的情况下 可能w有非常多的参数，你没能很好地拟合所有的参数，而b只是单个数字，几乎所有的参数都集中在w中 而不是b中，即使你加上了最后这一项，实际上也不会起到太大的作用。因为b只是大量参数中的一个参数。</p><h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><p>在神经网络中，你的正则项定义如下：</p><script type="math/tex; mode=display">\frac{\lambda}{2m}||W^{[l]}||^{2}_F</script><script type="math/tex; mode=display">||W^{[l]}||^{2} = \sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2</script><p>这个矩阵的范数称为矩阵的弗罗贝尼乌斯范数，使用角标F标记。由于线性代数中某些神秘的技术原因这不叫矩阵的L2范数而是称为矩阵的弗罗贝尼乌斯范数，它表示矩阵中元素的平方和。    </p><h3 id="为什么正则化可以解决过拟合"><a href="#为什么正则化可以解决过拟合" class="headerlink" title="为什么正则化可以解决过拟合"></a>为什么正则化可以解决过拟合</h3><p>看个例子</p><p><img src="https://i.loli.net/2020/04/25/l2HVWaIUoC9Q76A.png" style="zoom: 50%;"></p><p>在高方差的情况下，当你把lambda的值设置的很大，就相当于把W设置为非常接近0的值。也就是说隐藏层的影响会很小，因此这个网络最终就相当于逻辑回归模型。但是lambda存在一个中间值，可以把高偏差这种情况变成”just right”。</p><h3 id="另一种常见正则化——随机失活正则化-丢弃法-dropout"><a href="#另一种常见正则化——随机失活正则化-丢弃法-dropout" class="headerlink" title="另一种常见正则化——随机失活正则化(丢弃法 dropout)"></a>另一种常见正则化——随机失活正则化(丢弃法 dropout)</h3><p>这种方法就是在你的网络上，遍历每个节点。然后以一定的概率丢弃节点，最后形成一个小的多的网络，在这上面进行反向传播</p><p><img src="https://i.loli.net/2020/04/25/De31642s5GbaMJv.png" style="zoom: 80%;"></p><p>下面看个栗子，如何用代码实现丢弃法，（反向随机失活）</p><p>首先定义一个阈值keep.prob = 0.8,然后随机生成一个新的矩阵 d3 = np.random.rand(a3.shape[0],a3.shape[1]) &lt; keep.prob。在这个矩阵中每个元素有80%的概率为1,20%的概率为0（严格来说，这是一个True和False的矩阵，但是在python中这样是可行的）。 a3 = np.multiply(a3,d3)或者 a3 *= d3。这样就可以实现随机丢弃了。但是到这还没结束，需要以下这一步骤 a3 /=  keep.prob。来解释一下它。假设a3层有50个隐藏单元，所以a3的维数为50x1，如果是矢量化运算则为50 x m。每个单元有80%的概率保留，20%的概率丢弃，这意味着平均下来有10个单元被丢弃。而<script type="math/tex">z^{[4]} = w^{[4]}a^{[3]}+b^{[4]}</script> 。所以<script type="math/tex">a^{[3]}</script>的期望值会减少20%,e为了不让<script type="math/tex">z^{[4]}</script>的期望不被减少，就让<script type="math/tex">a^{[3]}</script>除以0.8，这样就可以修正期望值。这就是反向随机失活。需要注意的是，在每次迭代训练中，每次丢弃的都应该不同，而不是一直丢弃相同的单元。</p><h4 id="理解随机失活"><a href="#理解随机失活" class="headerlink" title="理解随机失活"></a>理解随机失活</h4><p>使用随机失活后，好像使用一个小的网络，就可以实现正则化。那么是为什么是这样呢？因为对于某个隐藏单元来说，它的每个输入都可能被丢弃，所以会尽可能的分散权重，不让某个输入的权重过大。这样就有了收缩权重以及防止过拟合的功能。准确的来讲，随机失活应该被看做一种自适应而不是正则化。</p><p>在网络上使用这张方法时，不同的隐藏层可以使用 不同的阈值，比如某些层你认为不会过拟合，则将阈值设为1,。但是这么做的代价是超参数过多导致运行较慢。另一种方法是在某些隐藏层设定相同的阈值，然后其它层不设置。</p><h3 id="其他正则化技术"><a href="#其他正则化技术" class="headerlink" title="其他正则化技术"></a>其他正则化技术</h3><h4 id="数据集增广-data-augmentation"><a href="#数据集增广-data-augmentation" class="headerlink" title="数据集增广(data augmentation)"></a>数据集增广(data augmentation)</h4><p>我们知道，增加训练集，可以解决过拟合问题。所以在现有数据集的情况下，我们可以对图片进行一些处理，；来新增数据，比如对图片进行旋转，放大，裁剪等等。这样我们会得到新的数据集。这也是解决过拟合的一种手段。</p><h4 id="早终止法-early-stopping"><a href="#早终止法-early-stopping" class="headerlink" title="早终止法(early stopping)"></a>早终止法(early stopping)</h4><p>这种方法就是画出在训练集和开发集上代价函数关于迭代次数的图像。在开发集的代价函数最小时提前终止训练。</p><h2 id="优化网络"><a href="#优化网络" class="headerlink" title="优化网络"></a>优化网络</h2><h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>首先如何归一化呢？先算出输入x的平均值，再全体减去均值。然后令σ^2等于 Xi**2之和除以m ，最后在同除以σ^2。同时也要对测试集，开发集进行归一化。</p><h4 id="为什么要归一化"><a href="#为什么要归一化" class="headerlink" title="为什么要归一化"></a>为什么要归一化</h4><p>因为不用的特征的范围是不同的，有的范围从0-1，有的0-100，这就会导致权重比例不平衡，并且会导致梯度下降很慢。当归一化之后，数据范围都是相近的，就不会出现上述情况了。</p><h3 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h3><p>当训练神经网络时我们会遇到一个问题，尤其是当训练层数非常多的神经网络时。这个问题就是梯度的消失和爆炸 它的意思是当你在训练一个深度神经网络的时候，损失函数的导数或者说斜率有时会变得非常大或者非常小甚至是呈指数级减小，这使训练变得很困难。举个栗子，你的激活函数为线性函数，当你的网络非常深，并且权重矩阵大于1的时候这个时候就会出现梯度爆炸的问题，事实上的最后的预测值是指数级增长的。同样，当权重矩阵的值小于1时，就会出现梯度消失的问题。</p><h4 id="如何尽量避免梯度消失和梯度爆炸"><a href="#如何尽量避免梯度消失和梯度爆炸" class="headerlink" title="如何尽量避免梯度消失和梯度爆炸"></a>如何尽量避免梯度消失和梯度爆炸</h4><ul><li>随机初始化权重矩阵</li></ul><p>假设你的激活函数为ReLu，那么可以这样初始化：</p><script type="math/tex; mode=display">W^{[l]} = np.random.randn(shape) * np.sqrt(\frac{2}{n^{[l-1]}})</script><p>如果是tanh：</p><script type="math/tex; mode=display">W^{[l]} = np.random.randn(shape) * np.sqrt(\frac{1}{n^{[l-1]}})</script><p>或者</p><script type="math/tex; mode=display">W^{[l]} = np.random.randn(shape) * np.sqrt(\frac{2}{n^{[l-1]}+n^{[l]}})</script>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 方差偏差 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣每日一题</title>
      <link href="/posts/206c9e3b.html"/>
      <url>/posts/206c9e3b.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="力扣每日一题（力扣官网）"><a href="#力扣每日一题（力扣官网）" class="headerlink" title="力扣每日一题（力扣官网）"></a>力扣每日一题（<a href="https://leetcode-cn.com/" target="_blank" rel="external nofollow noopener noreferrer">力扣官网</a>）</h1><p>今天开始 记录力扣上刷的题目，目的就是防止偷懒。。。做题顺序的话是看那道题目不顺眼，就先把那道题目做了！若无特殊声明，所有代码语言都是python3。下面直接开始做题。</p><a id="more"></a><h2 id="1-数字-n-代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且-有效的-括号组合"><a href="#1-数字-n-代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且-有效的-括号组合" class="headerlink" title="1.数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合"></a>1.数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合</h2><p>看到这道题 第一反应就是暴力法，直接列出所有可能性，然后判断是否正确就行了。但是觉得这样不是很好就没有去实现，实际操作应该是可行的。除了暴力法，还能想到什么办法呢，答案就是二叉树。因为括号分左右，而二叉树正好有左子树和右子树，所以这题其实就是搜索二叉树符合条件的节点。然后分析一下这可二叉树有什么特点：</p><ul><li>二叉树的根节点一定是  “(“，因为如果是右括号就没有正确答案了</li><li>在左括号有剩余的情况下，就可以生成左节点，最多添加n个</li><li>插入右括号的前提是 左括号的个数大于右括号（这里说的是生成节点上的，而不是剩余的括号个数）</li></ul><p>可以画个草图看一下：</p><p><img src="https://i.loli.net/2020/04/09/wCIGu9KPV5JFtO1.png" alt></p><p>红括号中就是显然错误的分支，没有必要继续往下遍历，也就是插入右括号时没有满足 第三个特点。</p><p>而黑色括号括起来的就是正确的结点。图中没有画出所有的结点。有兴趣的可以自己画画。</p><p>接下来就直接来实现代码：</p><p>首先。需要左括号，右括号的个数，然后一个result保存最终结果，tmp保存路径，也就是到达哪个节点。接下来然后直接深度遍历：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def generateParenthesis(self, n):</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        self.dfs(res, n, n, &#39;&#39;)</span><br><span class="line">        return res</span><br><span class="line">        </span><br><span class="line">    def dfs(self, res, left, right, tmp):</span><br><span class="line">        if left &#x3D;&#x3D; 0 and right &#x3D;&#x3D; 0:</span><br><span class="line">            res.append(tmp)</span><br><span class="line">            return</span><br><span class="line">        if left &gt; 0:</span><br><span class="line">            self.dfs(res, left - 1, right, tmp + &#39;(&#39;)</span><br><span class="line">        if left &lt; right:</span><br><span class="line">            self.dfs(res, left, right - 1, tmp + &#39;)&#39;)</span><br></pre></td></tr></table></figure><hr><h2 id="2-给定一个字符串，逐个翻转字符串中的每个单词。"><a href="#2-给定一个字符串，逐个翻转字符串中的每个单词。" class="headerlink" title="2.给定一个字符串，逐个翻转字符串中的每个单词。"></a>2.给定一个字符串，逐个翻转字符串中的每个单词。</h2><p>这道题目怎么讲呢，如果调用api的话就很简单，利用split和reverse函数，可以直接得到结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverseWords</span><span class="params">(self, s: str)</span> -&gt; str:</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">" "</span>.join(reversed(s.split()))</span><br></pre></td></tr></table></figure><p>如果不用reversed，split，join这几个函数，要怎么实现呢？ 其实我一贯秉承能偷懒就绝不多动一下的理念，哈哈，所以就直接用最笨的方法吧。首先对于一个字符串，我们要将他分割为一个一个的单词，最后反向输出得到最终结果。大致思路就是这样，然后我们需要考虑一下异常情况，就是 字符串 首部出现空格，中间出现多个空格的情况做处理，也就是下面几种情况：</p><ol><li><p>首先处理首部的字符串，确保第一个字符不为空格，如果为空格，则去除</p></li><li><p>用两个指针，来循环字符串，因为我们需要判断什么时候将字符组成一个字符串，而字符串中间出现的空格符就是标志</p></li><li><p>两个指针的另一个目的在于，当两个单词之间，出现多个空格时，单指针无法判断，我们需要双指针来判断：</p><ul><li>当左指针不为空，右指针不为空，说明这个单词还没结束</li><li>当左指针不为空，右指针为空时，确定前面的字符组成一个单词</li><li>当左指针为空，右指针为空时，说明处在中间的空白符，继续向下遍历</li><li>当左指针为空，右指针不为空时，说明开始处理下一个单词</li></ul></li><li><p>最后得到一个数组，里面按顺序放好单词，只要反向遍历数组，就能得到结果</p></li></ol><p>直接上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverseWords1</span><span class="params">(s)</span>:</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="comment"># 去除头空格</span></span><br><span class="line"><span class="keyword">if</span> len(s) == <span class="number">0</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> s[<span class="number">0</span>] == <span class="string">' '</span>:</span><br><span class="line">s = s[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">p,q = <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">length = len(s)</span><br><span class="line">word  = <span class="string">''</span></span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="comment">##当指针到达字符串末尾时，结束循环，并将最后一个单词加入，如果是空白字符串，就不加入</span></span><br><span class="line"><span class="keyword">if</span> q == length - <span class="number">1</span>:</span><br><span class="line"><span class="keyword">if</span> s[p] != <span class="string">' '</span> :</span><br><span class="line">word = word + s[p]</span><br><span class="line"><span class="keyword">if</span> s[q] != <span class="string">' '</span>:</span><br><span class="line">word = word + s[q]</span><br><span class="line"><span class="keyword">if</span> word == <span class="string">''</span> <span class="keyword">or</span> word == <span class="string">' '</span>:</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">words.append(word)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> q &gt; length - <span class="number">1</span>:</span><br><span class="line"><span class="keyword">if</span> s[p] != <span class="string">' '</span>:</span><br><span class="line">word = word + s[p]</span><br><span class="line"><span class="keyword">if</span> word == <span class="string">""</span> <span class="keyword">or</span> word == <span class="string">' '</span>:</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">words.append(word)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> s[p] != <span class="string">' '</span> <span class="keyword">and</span> s[q] != <span class="string">' '</span>:</span><br><span class="line">word = word + s[p]</span><br><span class="line">word = word + s[q]</span><br><span class="line">p = p + <span class="number">2</span></span><br><span class="line">q = q + <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> s[p] != <span class="string">' '</span> <span class="keyword">and</span> s[q] == <span class="string">' '</span>:</span><br><span class="line">word = word + s[p]</span><br><span class="line">words.append(word)</span><br><span class="line">word = <span class="string">''</span></span><br><span class="line">p = p + <span class="number">2</span></span><br><span class="line">q = q + <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> s[p] == <span class="string">' '</span> <span class="keyword">and</span> s[q] != <span class="string">' '</span>:</span><br><span class="line"></span><br><span class="line">words.append(word)</span><br><span class="line">word = <span class="string">''</span></span><br><span class="line">p = p + <span class="number">1</span></span><br><span class="line">q = q + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> s[p] == <span class="string">' '</span> <span class="keyword">and</span> s[q] == <span class="string">' '</span>:</span><br><span class="line"></span><br><span class="line">p = p + <span class="number">2</span></span><br><span class="line">q = q + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">length = len(words) - <span class="number">1</span></span><br><span class="line">s = <span class="string">''</span></span><br><span class="line"><span class="keyword">while</span> length &gt; <span class="number">-1</span>:</span><br><span class="line"><span class="keyword">if</span> words[length] == <span class="string">''</span>:</span><br><span class="line">length = length - <span class="number">1</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">s = s + words[length] + <span class="string">' '</span></span><br><span class="line">length = length - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">length = len(s)</span><br><span class="line">s = s[:length<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><p>这个代码写的很粗糙，因为只是简单实现这种思路，仅供借鉴，当不得真~</p><hr><h2 id="3-鸡蛋掉落"><a href="#3-鸡蛋掉落" class="headerlink" title="3.鸡蛋掉落"></a>3.鸡蛋掉落</h2><p>这道题目是这样的，假设你有N个蛋，这个蛋从某层楼扔下来不会碎，一旦超过这一层，就会碎，而楼共有K层，问最少扔多少次，可以找出这个临界层？</p><p>先分下一下，这里所说的最少扔多少次的意思，其实就是在最坏情况下，要扔多少次。考虑清楚这个，我们来分析一下题目。其实刚看到这个题目，第一反应就是二分法这样每次可以缩减一半的范围。然后我们现在来从最简答的情况开始分析：</p><ol><li>N=1,K=100。也就是在这人只有一个蛋，楼层100层的情况。这种情况下显然最少要扔100次，才能确定，因为只有一个蛋，所以只能从1层开始扔，如果第一层就碎了，说明临界层为1，若是第二层碎，说明临界层为2……直到100层，所以最少次数需要100次，才能找出</li><li>N=<script type="math/tex">\infty</script>,K=100。这种情况下就可以用刚才说到的二分法，我们可以直接在50层扔，如果碎了，说明临界层在0-50，如果没有碎，说明在50-100层。然后在取中间数，直到不可以再分。显然这种情况下，可以得到一个公式<script type="math/tex">2^{M}\ge100</script>,也就是<script type="math/tex">M\ge \log_2100</script>,取个整数，也就是M=7</li></ol><p>下面看稍微复杂的一些情况：</p><ol><li><p>N=2，K=100。现在你有两个蛋，该如何确定临界层呢？虽然二分法不能用了，但是我们可以借鉴思路。一共有两个蛋，那么我们用第一个蛋来确定范围，我们将100 划分为0-10,10-20……这样的间隔。我们用第一个蛋在第10层，20层……100层的地方按顺序扔，如果他在某一层碎了，那么就可以用第二个蛋在刚刚的区间中来具体确定。比如说在第十层楼扔的时候碎了，那么再用第二个蛋从第一层一直扔到第九层，那么一共就需要十次。假设在第100层的时候才碎，那么从第91扔到99，又扔了9次，加上第一个蛋用来确定范围扔了十次，那么一共就是19次。这样就得到找出临界层的最少次数。我们来思考一下，虽然得到了最少次数，但是这个值是分布在10~19之间的，有没有办法让这个值更均匀一点？</p><p>首先看到造成这个值的范围的原因是因为在分间隔的时候，是等间距分的，这就造成了当第一个鸡蛋扔的范围越大时，由于第二个鸡蛋要具体确定的楼层扔的次数都为9，所以值就是这样一个范围。那么现在我们将这个间隔不均匀分布，来看看是什么情况。</p></li><li><p>依旧是 N=2，K=100。这次这样来分，第一个区域为n，第二个区域为n-1，直到最有一个区域为1，这样的话，第一个鸡蛋每确定一个区域，第二个鸡蛋所需要检验的次数也会减1。这样总次数应该会平均一些。我们来计算一下。首先确定n的值，也就是</p><script type="math/tex; mode=display">1 + 2 +3 +...+n = \frac{n(n+1)}{2} \ge 100</script><p>这样n取整数为14，这样我们将100就划分为 14,  27，39，50，60,  69，77， 84， 90， 95， 99， 100。因为是取整数，所以最后不是继续加3，而是加1。那么一共分为12个区域，也就是说第一个鸡蛋最多扔十二次。如果第一个鸡蛋在14层碎了，那么需要用第二个鸡蛋来检验第1-13层，加上第一个鸡蛋扔的一次，就是14次，如果在27层碎了，那就要检验15-26层一共12层，加上第一个鸡蛋扔的两次一共14次。。。如果说第一个鸡蛋一直扔到最后一块区域才碎，那么第二个鸡蛋就不需要检验了，因为最后一个区域就一层楼，所以需要12次。也就是说按这种方式，至少需要扔14次就可以找出临界层。的确次数要比刚才的少。</p></li></ol><p>其实说到现在，我们只是解决了有两个蛋的情况，下面来看看更加复杂的情况，也就是楼层和鸡蛋都不确定的情况</p><p>假设楼层为K层，鸡蛋有N个，找出临界层所需要的最少次数为M。其实要找出来的就是M关于K，N的函数，假定这个函数为<strong>M（K,N）</strong>。我们可以先整个表格看一下(列为楼层，行为鸡蛋个数)。</p><div class="table-container"><table><thead><tr><th style="text-align:center">K\N</th><th>1</th><th>2</th><th>3</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td>1</td><td>1</td><td>1</td></tr><tr><td style="text-align:center">2</td><td>2</td><td></td><td></td></tr><tr><td style="text-align:center">3</td><td>3</td><td></td></tr></tbody></table></div><p>   可以看到，当楼层为1或者鸡蛋个数为时，表格非常好填。但是当其都大于1时，就需要思考一下了。</p><p>需要考虑的是，第一个鸡蛋扔在哪里，其实我们也不清楚，假设第一个鸡蛋扔在了第h层，那么就得到了两种结果，一种是碎了，一种是没碎。    如果碎了，说明临界层在0-H层，如果没有碎，说明在H-K层之间。那么第一种情况下，还需要扔多少次呢，这个时候其实还是相同的问题，只是楼层和鸡蛋个数的变化，即次数为M(H-1,N-1)，如果是第二种情况，那么就是M(K-H,N)。其实到这里也都看出来是个递归问题。那么因为我们需要的是最坏的情况下的次数，所以取两种情况的最大值，加上第一次扔，所以有，在你第一层鸡蛋扔在第H层情况下所需要的总次数<script type="math/tex">M_H</script>，它就等于</p><script type="math/tex; mode=display">M_H = max\{M(H-1,N-1), M(K-H,N)\} + 1</script><p> 那么如何确定H呢，显然就是枚举，H取值范围1~K，即我们有<script type="math/tex">M_1,M_2,....M_k</script>，我们的需要的是这个里面的最小值，所以就是说总次数M，就等于</p><script type="math/tex; mode=display">M = min\{M_1,M_2,M_3...M_K \}</script><p>这样的话，终于算出了最终结果，其实还是挺复杂的一个问题，接下来我们就直接用代码实现吧</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">throwEgg</span><span class="params">(K,N)</span>:</span></span><br><span class="line"><span class="comment">#若楼高K为1，则一次</span></span><br><span class="line"><span class="keyword">if</span> K == <span class="number">1</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="comment">#创建 K+1 行 N+1列的数组(注意这里生成数组 不能使用[[0] * (N + 1)]*(K + 1)</span></span><br><span class="line"><span class="comment">#因为这样生成的数组，只是生成了k+1个引用，当修改值时会一起修改从而导致bug</span></span><br><span class="line">res = [[<span class="number">0</span>] * (N + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(K + <span class="number">1</span>)]</span><br><span class="line"><span class="comment">#如果 只有一个鸡蛋，那么次数就为楼高</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,N+<span class="number">1</span>):</span><br><span class="line">res[<span class="number">1</span>][i] = <span class="number">1</span></span><br><span class="line">m = <span class="number">-1</span></span><br><span class="line"><span class="comment">#遍历所有楼层的情况</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,K+<span class="number">1</span>):</span><br><span class="line"><span class="comment">#在指定楼层，遍历所有鸡蛋的情况，这里是通过最基本的情况，去求解复杂的情况</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, N + <span class="number">1</span>):</span><br><span class="line">res[i][j] = <span class="number">1</span> + res[i - <span class="number">1</span>][j - <span class="number">1</span>] + res[i - <span class="number">1</span>][j]</span><br><span class="line"><span class="keyword">if</span> res[i][N] &gt;= K:</span><br><span class="line">m = i</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">return</span> m</span><br></pre></td></tr></table></figure><p>这道题目写起来挺麻烦，并且这里没有使用递归求解，感觉递归会更麻烦。这道题其实还有更多的解法，这里不展示了，有空在继续更新。</p><hr><h2 id="4-交点"><a href="#4-交点" class="headerlink" title="4.交点"></a>4.交点</h2><p>题目描述：给定两条线段（表示为起点start = {X1, Y1}和终点end = {X2, Y2}），如果它们有交点，请计算其交点，没有交点则返回空值。要求浮点型误差不超过10^-6。若有多个交点（线段重叠）则返回 X 值最小的点，X 坐标相同则返回 Y 值最小的点。</p><p>乍一看我还觉得这道题目挺简单的。后来发现题目要求是线段而不是直线。。。然后发现这道题巨烦，倒不是多难，而是要讨论的情况太多。下面来具体看看有那些情况：</p><ol><li><p>当两条线段为铅垂线时，先讨论两条直线的横坐标，若不同，则没交点，如果相同，在讨论两条线段的位置关系：先判断线段哪条的最高点更高，然后在具体讨论位置关系：</p><ul><li><p>两条铅垂线平行，即无交点</p></li><li><p>两条铅垂线在一条直线上，首先要判断是否重合。这样先取两条线段中的左右端点。然后判断两条线段在纵轴上谁更”高”一点。在比较以后，将较高的那条线段叫第一条线FL,较低的那个端点为（fminx，fminy）,较高的那点记做（fmaxx，fmaxy）剩余的那条叫SL，较低的那个端点为（sminx，sminy）,较高的那点记做（smaxx，smaxy）。然后在分情况讨论：</p><ul><li>当fminy &gt; smax的时候，两线段无交点。</li><li>当fminy &lt;= smax的时候，线段相交，然后需要讨论fminy与sminy的关系：<ol><li>fminy &lt; = sminy,说明FL包含了SL，那么按题目要求交点即为(sminx,sminy)</li><li>fminy &gt; sminy,说明FL与SL相交，那么按题目要求交点即为(sminx,fminy)</li></ol></li></ul><p><img src="https://i.loli.net/2020/04/13/MOgbl2JqFDVYBTy.png" alt></p></li></ul></li><li><p>当两条线段为水平线时，先讨论两条直线的纵坐标，若不同，则没交点，如果相同，在讨论两条线段的位置关系：先判断线段哪条在坐标轴上更靠右，将较右的那条线段叫第一条线FL,较左边的那个端点为（fminx，fminy）,较右边的那点记做（fmaxx，fmaxy）剩余的那条叫SL，较左的那个端点为（sminx，sminy）,较右的那点记做（smaxx，smaxy）然后在具体讨论位置关系：</p><ul><li><p>两条水平线平行，即无交点</p></li><li><p>两条水平线在一直线上，然后继续分情况讨论：</p><ul><li>当fminx &gt; smaxx，无交点</li><li>当fminx &lt;= smaxx,线段相交，然后讨论fminx与sminx的关系：<ol><li>fminx &lt;= sminx,说明FL包含了SL，那么按题目要求交点即为(sminx,sminy)</li><li>fminx &gt; sminx, 说明FL与SL相交，那么按题目要求交点即为(fminx,fminy)</li></ol></li></ul><p><img src="https://i.loli.net/2020/04/13/NtdlKocbFOZLA2p.png" alt></p></li></ul></li><li><p>当斜率相同即平行时，若截距不同，则无交点，若截距相同，则在具体讨论位置关系，依旧将线段分为FL,SL，端点依旧是大的设为max，小的叫min</p><ul><li><p>当fminx &gt; smax 的时候，无交点</p></li><li><p>fminx &lt;= smax 时：</p><ul><li>fminx &lt;= sminx，交点就为(sminx,sminy)</li><li>fminx &gt; sminx, 交点就为(fminx,fminy)</li></ul><p><img src="https://i.loli.net/2020/04/13/uR4M9fzYSI5FtKi.png" alt></p></li></ul></li><li><p>当其中一条为铅垂线，一条为水平线的时候：</p><ul><li><p>当水平线的纵坐标 小于铅垂线的最小纵坐标 或者大于最大纵坐标，肯定无交点</p></li><li><p>当水平线的纵坐标在铅垂线的大小纵坐标之间的时候，如果水平线的左端点小于等于铅垂线的横坐标，右端点大于等于铅垂线的横坐标，则存在交点（铅垂线横坐标，水平线的纵坐标）</p><p><img src="https://i.loli.net/2020/04/13/R73ycL8sg2qN9If.png" alt></p></li></ul></li><li><p>最常见的情况，即斜率没什么规律的情况下，这个时候可以直接算出交点，利用简单的数学知识，可以推导出交点 x = (b2 - b1) / (k1 - k2)（b1，b2为两条直线的截距），然后用代入直线算出纵坐标y。之后就是讨论这个交点是否在两条线段之间，即是否在两条线段围出来的图形中。我采用交点到过两端点铅垂线的距离之和是否等于端点距离之和，如果等于说明在范围内，即交点有效，否则无效。</p><p><img src="https://i.loli.net/2020/04/13/MRH6CvsVBlTKLOr.png" style="zoom:50%;"></p></li></ol><p>如图所示，红黑两条线段相交，分别判断交点到左右两条黄线和上下两条黄线的距离之和 是否直接等于端点的距离。</p><p>逻辑分下完了，下面可以写代码了，我这里的代码其实还可以精简，但是目前还没做，仅供参考</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">judge</span><span class="params">(x1,y1,x2,y2,x1_1,y1_1,x2_1,y2_1,x,y)</span>:</span></span><br><span class="line">    <span class="comment"># if x1 &lt;= x &lt;= x2 and x1_1 &lt;= x &lt;= x2_1 and y1 &lt;= y &lt;= y2 and y2_1 &lt;= y &lt;= y1_1:</span></span><br><span class="line">    <span class="comment">#     return (x,y)</span></span><br><span class="line">    xdis1 = abs(x1-x2)</span><br><span class="line">    ydis1 = abs(y1-y2)</span><br><span class="line">    xtox1 = abs(x1-x)</span><br><span class="line">    xtox2 = abs(x-x2)</span><br><span class="line">    ytoy1 = abs(y1-y)</span><br><span class="line">    ytoy2 = abs(y-y2)</span><br><span class="line">    xdis2 = abs(x1_1-x2_1)</span><br><span class="line">    ydis2 = abs(y1_1-y2_1)</span><br><span class="line">    xtox1_1 = abs(x - x1_1)</span><br><span class="line">    xtox2_1 = abs(x - x2_1)</span><br><span class="line">    ytoy1_1 = abs(y - y1_1)</span><br><span class="line">    ytoy2_1 = abs(y - y2_1)</span><br><span class="line">    <span class="keyword">if</span> xdis1 == (xtox1 + xtox2) <span class="keyword">and</span> ydis1 == (ytoy1 + ytoy2) \</span><br><span class="line">        <span class="keyword">and</span> xdis2 == (xtox1_1 + xtox2_1) <span class="keyword">and</span> ydis2 == (ytoy1_1 + ytoy2_1):</span><br><span class="line">        <span class="keyword">return</span> (x,y)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersection</span><span class="params">(self, start1: List[int], end1: List[int], start2: List[int], end2: List[int])</span> -&gt; List[float]:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 第一条直线</span></span><br><span class="line">        y1 = start1.pop()</span><br><span class="line">        x1 = start1.pop()</span><br><span class="line">        y2 = end1.pop()</span><br><span class="line">        x2 = end1.pop()</span><br><span class="line">        <span class="comment"># 第二条直线</span></span><br><span class="line">        y1_1 = start2.pop()</span><br><span class="line">        x1_1 = start2.pop()</span><br><span class="line">        y2_1 = end2.pop()</span><br><span class="line">        x2_1 = end2.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x1 == x2:</span><br><span class="line">            Y1 = x1</span><br><span class="line">            k1 = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="keyword">elif</span> y1 == y2:</span><br><span class="line">            Y1 = y1</span><br><span class="line">            k1 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            k1 = (y2 - y1) / (x2 - x1)</span><br><span class="line">        <span class="keyword">if</span> x1_1 == x2_1:</span><br><span class="line">            Y1_1 = x1_1</span><br><span class="line">            k2 = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="keyword">elif</span> y1_1 == y2_1:</span><br><span class="line">            Y1_1 = y1_1</span><br><span class="line">            k2 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            k2 = (y2_1 - y1_1) / (x2_1 - x1_1)</span><br><span class="line">        b1 = -k1*x1 + y1</span><br><span class="line">        b2 = -k2*x1_1 + y1_1</span><br><span class="line">        <span class="keyword">if</span> k1 == k2:</span><br><span class="line">            <span class="comment">##两条 铅锤线</span></span><br><span class="line">            <span class="keyword">if</span> k1 == float(<span class="string">'inf'</span>):</span><br><span class="line">                <span class="comment">##相互平行</span></span><br><span class="line">                <span class="keyword">if</span> x1 != x1_1:</span><br><span class="line">                    <span class="keyword">return</span> []</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment">##判断 两条铅锤线是否有交点</span></span><br><span class="line">                    fminy = min(y1,y2)</span><br><span class="line">                    fmaxy = max(y1,y2)</span><br><span class="line">                    sminy = min(y1_1,y2_1)</span><br><span class="line">                    smaxy = max(y1_1,y2_1)</span><br><span class="line">                <span class="comment">## 判断两条线谁高一点</span></span><br><span class="line">                    <span class="keyword">if</span> fmaxy &gt;= smaxy:</span><br><span class="line">                        <span class="keyword">if</span> fminy &gt; smaxy:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">return</span> (x1,fminy)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> sminy &gt; fmaxy:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">return</span> (x1,sminy)</span><br><span class="line">            <span class="comment">##两条 水平线</span></span><br><span class="line">            <span class="keyword">elif</span> k1 == <span class="number">0</span>:</span><br><span class="line">                <span class="comment">##相互平行</span></span><br><span class="line">                <span class="keyword">if</span> y1 != y1_1:</span><br><span class="line">                    <span class="keyword">return</span> []</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment">##判断 两条水平线是否有交点</span></span><br><span class="line">                    fminx = min(x1,x2)</span><br><span class="line">                    fmaxx = max(x1,x2)</span><br><span class="line">                    sminx = min(x1_1,x2_1)</span><br><span class="line">                    smaxx = max(x1_1,x2_1)</span><br><span class="line">                    <span class="comment">##判断哪条长一点</span></span><br><span class="line">                    <span class="keyword">if</span> fmaxx &gt;= smaxx:</span><br><span class="line">                        <span class="keyword">if</span> fminx &gt; smaxx:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">return</span> (fminx,y1)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> sminx &gt; fmaxx:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">return</span> (sminx,y1)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># if fmaxx &lt; sminx or fminx &gt; smaxx:</span></span><br><span class="line">                    <span class="comment">#     return []</span></span><br><span class="line">                    <span class="comment"># if fmaxx &gt;= sminx:</span></span><br><span class="line">                    <span class="comment">#     return (fmaxx,y1)</span></span><br><span class="line">                    <span class="comment"># if fminx &lt;= smaxx:</span></span><br><span class="line">                    <span class="comment">#     return (x1, fminx)</span></span><br><span class="line">            <span class="comment">##两条斜线</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> b1 != b2:</span><br><span class="line">                    <span class="keyword">return</span> []</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> x1 &lt;= x2:</span><br><span class="line">                        fminx = x1</span><br><span class="line">                        <span class="comment">#这里实际上不是最小，但是为了区分对应，故意写成这样</span></span><br><span class="line">                        fminy = y1</span><br><span class="line">                        fmaxx = x2</span><br><span class="line">                        fmaxy = y2</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        fminx = x2</span><br><span class="line">                        <span class="comment"># 这里实际上不是最小，但是为了区分对应，故意写成这样</span></span><br><span class="line">                        fminy = y2</span><br><span class="line">                        fmaxx = x1</span><br><span class="line">                        fmaxy = y1</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> x1_1 &lt;= x2_1:</span><br><span class="line">                        sminx = x1_1</span><br><span class="line">                        <span class="comment">#这里实际上不是最小，但是为了区分对应，故意写成这样</span></span><br><span class="line">                        sminy = y1_1</span><br><span class="line">                        smaxx = x2_1</span><br><span class="line">                        smaxy = y2_1</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        sminx = x2_1</span><br><span class="line">                        <span class="comment"># 这里实际上不是最小，但是为了区分对应，故意写成这样</span></span><br><span class="line">                        sminy = y2_1</span><br><span class="line">                        smaxx = x1_1</span><br><span class="line">                        smaxy = y1_1</span><br><span class="line">                    <span class="comment">#判断哪条在坐标轴上更偏右</span></span><br><span class="line">                    <span class="keyword">if</span> fmaxx &gt;= smaxx:</span><br><span class="line">                        <span class="keyword">if</span> fminx &gt; smaxx:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">if</span> fminx &lt;= sminx:</span><br><span class="line">                                <span class="keyword">return</span> (sminx,sminy)</span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                <span class="keyword">return</span> (fminx,fminy)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> sminx &gt; fmaxx:</span><br><span class="line">                            <span class="keyword">return</span> []</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">if</span> sminx &lt; fminx:</span><br><span class="line">                                <span class="keyword">return</span> (fminx,fminy)</span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                <span class="keyword">return</span> (sminx,sminy)</span><br><span class="line">                    <span class="comment"># if fmaxx &lt; sminx or fminx &gt; smaxx:</span></span><br><span class="line">                    <span class="comment">#     return []</span></span><br><span class="line">                    <span class="comment"># if fmaxx &gt;= sminx:</span></span><br><span class="line">                    <span class="comment">#     return (sminx, sminy)</span></span><br><span class="line">                    <span class="comment"># if fminx &lt;= smaxx:</span></span><br><span class="line">                    <span class="comment">#     return (fminx,fminy)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> k1 == float(<span class="string">'inf'</span>) <span class="keyword">and</span> k2 == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> y1 &lt;= y2:</span><br><span class="line">                fminy = y1</span><br><span class="line">                fmaxy = y2</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fminy = y2</span><br><span class="line">                fmaxy = y1</span><br><span class="line">            <span class="keyword">if</span> x1_1 &lt;= x2_1:</span><br><span class="line">                sminx = x1_1</span><br><span class="line">                smaxx = x2_1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sminx = x2_1</span><br><span class="line">                smaxx = x1_1</span><br><span class="line">            <span class="keyword">if</span> sminx &lt;= x1 <span class="keyword">and</span> smaxx &gt;= x1 <span class="keyword">and</span> y2 &gt;= fminy <span class="keyword">and</span> y2 &lt;= fmaxy:</span><br><span class="line">                <span class="keyword">return</span> (x1,y2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> k2 == float(<span class="string">'inf'</span>) <span class="keyword">and</span> k1 == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> y1_1 &lt;= y2_1:</span><br><span class="line">                sminy = y1_1</span><br><span class="line">                smaxy = y2_1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sminy = y2_1</span><br><span class="line">                smaxy = y1_1</span><br><span class="line">            <span class="keyword">if</span> x1 &lt;= x2:</span><br><span class="line">                fminx = x1</span><br><span class="line">                fmaxx = x2</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fminx = x2</span><br><span class="line">                fmaxx = x1</span><br><span class="line">            <span class="keyword">if</span> fminx &lt;= x1_1 <span class="keyword">and</span> fmaxx &gt;= x1_1 <span class="keyword">and</span> y1 &gt;= sminy <span class="keyword">and</span> y1 &lt;= smaxy:</span><br><span class="line">                <span class="keyword">return</span> (x2, y1)</span><br><span class="line">        <span class="keyword">elif</span> k1 == float(<span class="string">'inf'</span>) <span class="keyword">and</span> k2 != <span class="number">0</span> <span class="keyword">and</span> k2 != float(<span class="string">'inf'</span>):</span><br><span class="line">            y = k2 * x1 + b2</span><br><span class="line">            <span class="keyword">return</span> judge(x1,y1,x2,y2,x1_1,y1_1,x2_1,y2_1,x1,y)</span><br><span class="line">        <span class="keyword">elif</span> k2 == float(<span class="string">'inf'</span>) <span class="keyword">and</span> k1 !=<span class="number">0</span> <span class="keyword">and</span> k1 != float(<span class="string">'inf'</span>):</span><br><span class="line">            y = k1 * x1_1 + b1</span><br><span class="line">            <span class="keyword">return</span> judge(x1, y1, x2, y2, x1_1, y1_1, x2_1, y2_1, x1_1, y)</span><br><span class="line"></span><br><span class="line">        x = (b2 - b1) / (k1 - k2)</span><br><span class="line">        y = k1*x + b1</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> judge(x1,y1,x2,y2,x1_1,y1_1,x2_1,y2_1,x,y)</span><br></pre></td></tr></table></figure><p>好了，这道题目暂时到这结束，不算很难，但是需要仔细分析。</p><h2 id="5-设计一个简化版的推特"><a href="#5-设计一个简化版的推特" class="headerlink" title="5.设计一个简化版的推特"></a>5.设计一个简化版的推特</h2><p>你的设计需要支持以下的几个功能：</p><ol><li>postTweet(userId, tweetId): 创建一条新的推文</li><li>getNewsFeed(userId): 检索最近的十条推文。每个推文都必须是由此用户关注的人或者是用户自己发出的。推文必须按照时间顺序由最近的开始排序。</li><li>follow(followerId, followeeId): 关注一个用户</li><li>unfollow(followerId, followeeId): 取消关注一个用户</li></ol><p>今天的题目比前两天都要简单，没有什么复杂的边界或者数学问题。可以直接利用两个字典来实现。具体分析一下功能</p><ol><li>声明两个字典content，star，分别存储用户发的twitter和关注，对应的key都为userid</li><li>发推特：<ul><li>利用time模块，记录时间戳，然后与twitterid 封装成 “twitterid-时间戳”的格式存入到content中</li><li>注意点，由于操作速度很快，可能需要sleep，以此分辨推特的先后顺序</li></ul></li><li>关注用户：<ul><li>先判断userid是否在star中，若不存在，则创建，然后加入对应的id</li></ul></li><li>取关<ul><li>先判断userid是否在star中，若存在，再判断取关对象的id是否在对应的value中，若存在，则移除</li></ul></li><li>获取最近的十条消息<ul><li>先从content中取出用户自己所发推特，如果用户没有关注对象，则直接按顺序返回用户的最近十条推特</li><li>若用户有关注对象，则取出对象id，然后从content中取出对应的推特（如果该用户发过推特），然后和用户所发推特组成新的列表。接下来遍历该列表。取出对应的value值，利用split得到对应id和时间戳，将其中时间戳最大的的放入结果集中，然后移除该值，进行下轮迭代。如果发现迭代出来的有相同id，则此轮迭代不计数，进行下一轮，总共取到十条记录为止</li></ul></li></ol><p>大致的思路就这样，没有难点，下面就附上代码，仅供参考：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Twitter</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.star = &#123;&#125;</span><br><span class="line">        self.content=&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postTweet</span><span class="params">(self, userId: int, tweetId: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compose a new tweet.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment">#运行速度太快。。无法精准计算时间，故休眠</span></span><br><span class="line">        time.sleep(<span class="number">0.001</span>)</span><br><span class="line">        ticks = time.time()</span><br><span class="line">        <span class="keyword">if</span> userId <span class="keyword">not</span> <span class="keyword">in</span> self.content:</span><br><span class="line">            self.content[userId] = []</span><br><span class="line">            self.content[userId].append(str(tweetId) + <span class="string">'-'</span> + str(ticks))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.content[userId].append(str(tweetId) + <span class="string">'-'</span> + str(ticks))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getNewsFeed</span><span class="params">(self, userId: int)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Retrieve the 10 most recent tweet ids in the user's news feed. Each item in the news feed must be posted by users who the user followed or by the user herself. Tweets must be ordered from most recent to least recent.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> userId <span class="keyword">in</span> self.content:</span><br><span class="line">            mycontent = copy.deepcopy(self.content[userId])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mycontent = []</span><br><span class="line">        <span class="keyword">if</span> userId <span class="keyword">in</span> self.star:</span><br><span class="line">            followees = copy.deepcopy(self.star[userId])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            followees = []</span><br><span class="line">        fcontent = []</span><br><span class="line">        res = []</span><br><span class="line">        tweetId = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> followees :</span><br><span class="line">            <span class="keyword">for</span> id <span class="keyword">in</span> followees:</span><br><span class="line">                <span class="comment">#判断用户是否发过twitter</span></span><br><span class="line">                <span class="keyword">if</span> id <span class="keyword">in</span> self.content:</span><br><span class="line">                    fcontent.extend(self.content[id])</span><br><span class="line"></span><br><span class="line">            mycontent.extend(fcontent)</span><br><span class="line">            <span class="comment">#print("mycontent",mycontent)</span></span><br><span class="line">            i=<span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt;= <span class="number">9</span>:</span><br><span class="line">                min = float(<span class="string">'-inf'</span>)</span><br><span class="line">                <span class="keyword">if</span> mycontent:</span><br><span class="line">                    <span class="keyword">for</span> val <span class="keyword">in</span> mycontent:</span><br><span class="line">                        <span class="comment">#print(val)</span></span><br><span class="line">                        tmp = val.split(<span class="string">'-'</span>)</span><br><span class="line">                        posttime = float(tmp[<span class="number">1</span>])</span><br><span class="line">                        <span class="keyword">if</span> posttime &gt; min:</span><br><span class="line">                            tweetId = tmp[<span class="number">0</span>]</span><br><span class="line">                            min = posttime</span><br><span class="line">                    <span class="keyword">if</span> tweetId <span class="keyword">not</span> <span class="keyword">in</span> res:</span><br><span class="line">                        res.append(tweetId)</span><br><span class="line">                        i = i + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    mycontent.remove(str(tweetId) + <span class="string">'-'</span> + str(min))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">                <span class="keyword">if</span> mycontent:</span><br><span class="line">                    id = mycontent.pop().split(<span class="string">'-'</span>)[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">if</span> id <span class="keyword">not</span> <span class="keyword">in</span> res:</span><br><span class="line">                        res.append(id)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">follow</span><span class="params">(self, followerId: int, followeeId: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Follower follows a followee. If the operation is invalid, it should be a no-op.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> followerId <span class="keyword">not</span> <span class="keyword">in</span> self.star:</span><br><span class="line">            self.star[followerId] = []</span><br><span class="line">            self.star[followerId].append(followeeId)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.star[followerId].append(followeeId)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unfollow</span><span class="params">(self, followerId: int, followeeId: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Follower unfollows a followee. If the operation is invalid, it should be a no-op.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> followerId <span class="keyword">in</span> self.star:</span><br><span class="line">            <span class="keyword">if</span> followeeId <span class="keyword">in</span> self.star[followerId]:</span><br><span class="line">                self.star[followerId].remove(followeeId)</span><br></pre></td></tr></table></figure><h2 id="6-两数相加-II"><a href="#6-两数相加-II" class="headerlink" title="6.两数相加 II"></a>6.两数相加 II</h2><p>要求：给你两个 非空 链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。</p><p>你可以假设除了数字 0 之外，这两个数字都不会以零开头。</p><p>进阶：</p><p>如果输入链表不能修改该如何处理？换句话说，你不能对列表中的节点进行翻转。</p><p>要求是很简单的，只要两数和，难点是数字是存放在链表中的，所以我们要写遍历链表，将取出的数字放进列表中。然后判断两个列表的长度，将长的设置为big，另一个叫small,然后在分析：</p><ol><li>首先 我们在small不为空的条件下，同时对small和big进行pop操作，然后将其相加，再判断是否和大于等于10，若大于等于10，则将结果减去10在将入res，同时将b置为1。否则直接将结果加入res，b置为0</li><li>然后在big不为空的情况下，计算big.pop与b的和。在重复条件一后面的判断。这里其实是相加的两个数位数不同的情况下的计算。</li><li>最后在big也为空列表的情况下，判断b是否为1，也就是是否存在进位的问题，若为1，则在res中加1。这里是计算20+80这种情况。</li></ol><p>最后我们有了结果集res。由于题目要求是返回链表，所以我们遍历结果集，重新生成链表就行了。</p><p>下面附上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addTwoNumbers</span><span class="params">(self, l1: ListNode, l2: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        arr1 = []</span><br><span class="line">        arr2 = []</span><br><span class="line">        f1 = f2 = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">while</span> f1:</span><br><span class="line">            arr1.append(l1.val)</span><br><span class="line">            <span class="keyword">if</span> l1.next != <span class="literal">None</span>:</span><br><span class="line">                l1 = l1.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                f1 = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> f2:</span><br><span class="line">            arr2.append(l2.val)</span><br><span class="line">            <span class="keyword">if</span> l2.next != <span class="literal">None</span>:</span><br><span class="line">                l2 = l2.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                f2 = <span class="literal">False</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> len(arr1) &gt;= len(arr2):</span><br><span class="line">            big = arr1</span><br><span class="line">            small = arr2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            big = arr2</span><br><span class="line">            small = arr1</span><br><span class="line">        <span class="comment">#b为进位数</span></span><br><span class="line">        b = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> small != []:</span><br><span class="line">            result = big.pop() + small.pop() + b</span><br><span class="line">            <span class="keyword">if</span>  result &gt;= <span class="number">10</span>:</span><br><span class="line">                res.insert(<span class="number">0</span>,result<span class="number">-10</span>)</span><br><span class="line">                b = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.insert(<span class="number">0</span>,result)</span><br><span class="line">                b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> big != []:</span><br><span class="line">            result = big.pop() + b</span><br><span class="line">            <span class="keyword">if</span>  result &gt;= <span class="number">10</span> :</span><br><span class="line">                res.insert(<span class="number">0</span>,result<span class="number">-10</span>)</span><br><span class="line">                b = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.insert(<span class="number">0</span>,result)</span><br><span class="line">                b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> big == [] <span class="keyword">and</span> b == <span class="number">1</span>:</span><br><span class="line">            res.insert(<span class="number">0</span>,b)</span><br><span class="line"></span><br><span class="line">        cache = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> res:</span><br><span class="line">            tmp = ListNode(i)</span><br><span class="line">            <span class="keyword">if</span> cache != <span class="literal">None</span>:</span><br><span class="line">                cache.next = tmp</span><br><span class="line">                cache = tmp</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                head = ListNode(i)</span><br><span class="line">                cache = head</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure><h2 id="7-两数之和"><a href="#7-两数之和" class="headerlink" title="7.两数之和"></a>7.两数之和</h2><p>要求：给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。</p><p>今天的题目很简单，利用python可以很简单的实现。遍历数组，用target减去当前值，若他们的差在剩余的数组中，则有解，否则进行下一轮迭代。</p><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums: List[int], target: int)</span> -&gt; List[int]:</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        length = len(nums)</span><br><span class="line">        <span class="keyword">while</span> i &lt; length - <span class="number">1</span>:</span><br><span class="line">            sub = target - nums[i]</span><br><span class="line">            <span class="keyword">if</span> sub <span class="keyword">in</span> nums[i + <span class="number">1</span>:]:</span><br><span class="line">                <span class="keyword">return</span> (i,i + nums[i + <span class="number">1</span>:].index(sub)+<span class="number">1</span>)</span><br><span class="line">            i += <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="8-合并区间"><a href="#8-合并区间" class="headerlink" title="8.合并区间"></a>8.合并区间</h2><p>要求：给出一个区间的集合，请合并所有重叠的区间。</p><p>就是说给出[1,4],[4,5]可以将其合并成[1,5]，即两个区间如果有交集，就可以将他们合并。对于这种问题，我们可以将集合先从小到大排序，然后从头开始比较，分别有以下几种情况</p><ol><li>当左区间的右端点小于右区间的左端点时，不能合并</li><li>当左区间的右端点大于等于右区间的左端点时，可以合并，但是要分情况：<ul><li>当左区间的左端点A小于右区间的左端点C时，合并后区间的左端点的值为A,否则为C</li><li>当左区间的右端点B小于右区间的右端点D时，合并后区间的右端点的值为D,否则为B</li></ul></li></ol><p>这样就得到了合并后的区间，我们将其插入到原集合中，并从原集合中删除被合并的区间，进行下一轮迭代。这样到最后就可以得到所有合并后的区间，下面贴上代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(self, intervals: List[List[int]])</span> -&gt; List[List[int]]:</span></span><br><span class="line">        <span class="keyword">if</span> intervals == []:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        row, col = len(intervals), len(intervals[<span class="number">0</span>])</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        intervals.sort()</span><br><span class="line">        <span class="keyword">while</span> i + <span class="number">1</span> &lt; row:</span><br><span class="line">            <span class="keyword">if</span> intervals[i][col - <span class="number">1</span>] &gt;= intervals[i + <span class="number">1</span>][<span class="number">0</span>]:</span><br><span class="line">                tmp1 = intervals[i]</span><br><span class="line">                tmp2 = intervals[i + <span class="number">1</span>]</span><br><span class="line">                mergearr = []</span><br><span class="line">                <span class="keyword">if</span> intervals[i][<span class="number">0</span>] &lt;= intervals[i + <span class="number">1</span>][<span class="number">0</span>]:</span><br><span class="line">                    mergearr.append(intervals[i][<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mergearr.append(intervals[i + <span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">if</span> intervals[i][col - <span class="number">1</span>] &gt;= intervals[i + <span class="number">1</span>][col - <span class="number">1</span>]:</span><br><span class="line">                    mergearr.append(intervals[i][col - <span class="number">1</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mergearr.append(intervals[i + <span class="number">1</span>][col - <span class="number">1</span>])</span><br><span class="line">                intervals.remove(tmp1)</span><br><span class="line">                intervals.remove(tmp2)</span><br><span class="line">                intervals.insert(<span class="number">0</span>, mergearr)</span><br><span class="line">                row = len(intervals)</span><br><span class="line">                i = <span class="number">0</span></span><br><span class="line">                intervals.sort()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> intervals</span><br></pre></td></tr></table></figure><h2 id="9-跳跃游戏"><a href="#9-跳跃游戏" class="headerlink" title="9.跳跃游戏"></a>9.跳跃游戏</h2><p>要求：给定一个非负整数数组，你最初位于数组的第一个位置。数组中的每个元素代表你在该位置可以跳跃的最大长度。判断你是否能够到达最后一个位置。</p><p>今天的题目，用官方提供的贪心算法来解决。因为我用的是递归方法，并且用到了全局变量，导致在跑测试用例时不准确，等之后调整好了在提供我的思路。现在先来看一下官方的：</p><p>设想一下，对于数组中的任意一个位置 <script type="math/tex">y</script>，我们如何判断它是否可以到达？根据题目的描述，只要存在一个位置 <script type="math/tex">x</script>，它本身可以到达，并且它跳跃的最大长度为 <script type="math/tex">x + \textit{nums}[x]</script>，这个值大于等于 <script type="math/tex">y</script>，即 <script type="math/tex">x + \textit{nums}[x] \geq y</script>，那么位置 <script type="math/tex">y</script> 也可以到达。</p><p>换句话说，对于每一个可以到达的位置 <script type="math/tex">x</script>，它使得 <script type="math/tex">x+1, x+2, \cdots, x+\textit{nums}[x]</script>这些连续的位置都可以到达。</p><p>这样以来，我们依次遍历数组中的每一个位置，并实时维护 最远可以到达的位置。对于当前遍历到的位置 <script type="math/tex">x</script>，如果它在 最远可以到达的位置 的范围内，那么我们就可以从起点通过若干次跳跃到达该位置，因此我们可以用 <script type="math/tex">x + \textit{nums}[x]</script>更新 最远可以到达的位置。</p><p>在遍历的过程中，如果 最远可以到达的位置 大于等于数组中的最后一个位置，那就说明最后一个位置可达，我们就可以直接返回 True 作为答案。反之，如果在遍历结束后，最后一个位置仍然不可达，我们就返回 False 作为答案。</p><p>以题目中的示例一</p><p>[2, 3, 1, 1, 4]<br>为例：</p><p>我们一开始在位置 0，可以跳跃的最大长度为 2，因此最远可以到达的位置被更新为 2；</p><p>我们遍历到位置 1，由于 <script type="math/tex">1 \leq 2</script>，因此位置 1 可达。我们用 11加上它可以跳跃的最大长度 3，将最远可以到达的位置更新为 4。由于 4大于等于最后一个位置 4，因此我们直接返回 True。</p><p>我们再来看看题目中的示例二</p><p>[3, 2, 1, 0, 4]<br>我们一开始在位置 0，可以跳跃的最大长度为 3，因此最远可以到达的位置被更新为 3；</p><p>我们遍历到位置 1，由于<script type="math/tex">1 \leq 3</script>，因此位置 1可达，加上它可以跳跃的最大长度 2 得到 3，没有超过最远可以到达的位置；</p><p>位置 2、位置 3 同理，最远可以到达的位置不会被更新；</p><p>我们遍历到位置 4，由于 4 &gt; 3，因此位置 4 不可达，我们也就不考虑它可以跳跃的最大长度了。</p><p>在遍历完成之后，位置 4 仍然不可达，因此我们返回 False.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canJump</span><span class="params">(self, nums: List[int])</span> -&gt; bool:</span></span><br><span class="line">        n, rightmost = len(nums), <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">if</span> i &lt;= rightmost:</span><br><span class="line">                rightmost = max(rightmost, i + nums[i])</span><br><span class="line">                <span class="keyword">if</span> rightmost &gt;= n - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="10-整数反转"><a href="#10-整数反转" class="headerlink" title="10.整数反转"></a>10.整数反转</h2><p>描述：给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。注意:</p><p>假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [<script type="math/tex">-2^{31},2^{31}-1</script>]。请根据这个假设，如果反转后整数溢出那么就返回 0。</p><p>这道题有很多解法，这里采用了字符串的方法.</p><ol><li>先判断是否为0 若为0，直接返回0</li><li>先判断正负号，如果是负数，先转换为整数</li><li>若为整数，将数字转化为字符串在遍历，拼接字符串：<ul><li>在转换为int类型。判断范围，不在范围内返回0 </li><li>若刚才的为负数，返回的时候添加负号</li></ul></li></ol><p>下面是代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reversestr</span><span class="params">(x)</span>:</span></span><br><span class="line">    s=<span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> tmp <span class="keyword">in</span> str(x):</span><br><span class="line">        s = tmp + s</span><br><span class="line">    x = int(s)</span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">-2</span>**<span class="number">31</span> <span class="keyword">or</span> x &gt;  <span class="number">2</span>**<span class="number">31</span><span class="number">-1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse</span><span class="params">(self, x: int)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> x == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span> </span><br><span class="line">        <span class="keyword">elif</span> x &lt; <span class="number">0</span>:</span><br><span class="line">            x = -x</span><br><span class="line">            <span class="keyword">return</span> -reversestr(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> reversestr(x)</span><br></pre></td></tr></table></figure><h2 id="11-两个栈实现队列"><a href="#11-两个栈实现队列" class="headerlink" title="11.两个栈实现队列"></a>11.两个栈实现队列</h2><p>描述：用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p><p>这道题目是很挺简单的。因为python的列表可以很方便的实现。</p><p><strong>-</strong> 题目要求队尾插入整数，可以用append</p><p><strong>-</strong> 队头实现删除功能，所以利用pop</p><p>附上代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CQueue</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.queue = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">appendTail</span><span class="params">(self, value: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self.queue.append(value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteHead</span><span class="params">(self)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> self.queue:</span><br><span class="line">            <span class="keyword">return</span> self.queue.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your CQueue object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = CQueue()</span></span><br><span class="line"><span class="comment"># obj.appendTail(value)</span></span><br><span class="line"><span class="comment"># param_2 = obj.deleteHead()</span></span><br></pre></td></tr></table></figure><h2 id="12-斐波那契数列"><a href="#12-斐波那契数列" class="headerlink" title="12.斐波那契数列"></a>12.斐波那契数列</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项。斐波那契数列的定义如下：</p><p>F(0) = 0,   F(1) = 1<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.</p><p>这个题目很简单，直接递归就行了。但是要注意的是，这里用到了一个装饰器—-lru_cache。因为这里面需要大量的重复计算。而lru_cache能把相对耗时的函数结果进行保存，避免传入相同的参数重复计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> lru_cache</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line"><span class="meta">    @lru_cache(None)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fib</span><span class="params">(self, n: int)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> n</span><br><span class="line">        <span class="keyword">return</span> (self.fib(n<span class="number">-1</span>) + self.fib(n<span class="number">-2</span>))%<span class="number">1000000007</span></span><br></pre></td></tr></table></figure><h2 id="13-青蛙跳台阶问题"><a href="#13-青蛙跳台阶问题" class="headerlink" title="13.青蛙跳台阶问题"></a>13.青蛙跳台阶问题</h2><p>描述：一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。</p><p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p><p>这题依旧可以看做是斐波那契数列，但是需要注意起始条件不同。当n=0时，应该返回1.另一种方法就是动态规划。</p><ul><li>状态定义： 设 dp 为一维数组，其中 dp[i] 的值代表 斐波那契数列第 $i$ 个数字 。</li><li><p>dp[i + 1] = dp[i] + dp[i - 1]dp[i+1]=dp[i]+dp[i−1] ，即对应数列定义 f(n + 1) = f(n) + f(n - 1)f(n+1)=f(n)+f(n−1) </p></li><li><p>初始状态： dp[0] = 1 dp[1] = 1，即初始化前两个数字；</p></li><li>返回值： dp[n] ，即斐波那契数列的第 n 个数字。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numWays</span><span class="params">(self, n: int)</span> -&gt; int:</span></span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(n):</span><br><span class="line">            a, b = b, a + b</span><br><span class="line">        <span class="keyword">return</span> a % <span class="number">1000000007</span></span><br></pre></td></tr></table></figure><h2 id="14-最小栈"><a href="#14-最小栈" class="headerlink" title="14.最小栈"></a>14.最小栈</h2><p>描述：设计一个支持 <code>push</code> ，<code>pop</code> ，<code>top</code> 操作，并能在常数时间内检索到最小元素的栈。</p><ul><li>push(x) —— 将元素 x 推入栈中。</li><li>pop() —— 删除栈顶的元素。</li><li>top() —— 获取栈顶元素。</li><li>getMin() —— 检索栈中的最小元素。</li></ul><p>这道题很简单，就不多说了，直接上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinStack</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.s = []</span><br><span class="line">        self.min = float(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, x: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self.s.append(x)</span><br><span class="line">        <span class="keyword">if</span> x &lt; self.min:</span><br><span class="line">            self.min = x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.s:</span><br><span class="line">            self.s.pop()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top</span><span class="params">(self)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> self.s:</span><br><span class="line">            <span class="keyword">return</span> self.s[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMin</span><span class="params">(self)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> self.s:</span><br><span class="line">            <span class="keyword">return</span> min(self.s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your MinStack object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = MinStack()</span></span><br><span class="line"><span class="comment"># obj.push(x)</span></span><br><span class="line"><span class="comment"># obj.pop()</span></span><br><span class="line"><span class="comment"># param_3 = obj.top()</span></span><br><span class="line"><span class="comment"># param_4 = obj.getMin()</span></span><br></pre></td></tr></table></figure><h2 id="15-层次遍历"><a href="#15-层次遍历" class="headerlink" title="15.层次遍历"></a>15.层次遍历</h2><p>描述：给你一个二叉树，请你返回其按 <strong>层序遍历</strong> 得到的节点值。 （即逐层地，从左到右访问所有节点）</p><p>示例：<br>二叉树：[3,9,20,null,null,15,7],</p><p>​    3</p><p>   / \<br>  9  20<br>    /  \<br>   15   7<br>返回其层次遍历结果：</p><p>[<br>  [3],<br>  [9,20],<br>  [15,7]<br>]</p><p><strong>解题思路</strong></p><p>只要遍历二叉树同时记录对应节点的位置就行了</p><ul><li>遍历二叉树，记录节点值，同时记录位置</li></ul><ul><li>当二叉树左子树不为空，位置加一，递归</li><li>当二叉树右子树不为空，且左子树为空，位置加一，递归</li><li>遍历过程中，不要重复追加[]就可以了</li></ul><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    res = [[]]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span><span class="params">(self, root: TreeNode)</span> -&gt; List[List[int]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root :</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        self.res = [[]]</span><br><span class="line">        self.dfs(root,<span class="number">0</span>) </span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,root,pos)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.res[pos].append(root.val)</span><br><span class="line">        <span class="keyword">if</span> root.left != <span class="literal">None</span>:</span><br><span class="line">            pos += <span class="number">1</span></span><br><span class="line">            <span class="comment">#判断该层节点值是否已经开始记录</span></span><br><span class="line">            <span class="keyword">if</span> len(self.res) &lt; pos+<span class="number">1</span>:</span><br><span class="line">                self.res.append([])</span><br><span class="line">            self.dfs(root.left,pos)</span><br><span class="line">        <span class="keyword">if</span> root.right != <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> root.left == <span class="literal">None</span>:</span><br><span class="line">                pos += <span class="number">1</span></span><br><span class="line">                <span class="comment">#判断该层节点值是否已经开始记录</span></span><br><span class="line">                <span class="keyword">if</span> len(self.res) &lt; pos+<span class="number">1</span>:</span><br><span class="line">                    self.res.append([])</span><br><span class="line">            self.dfs(root.right,pos)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br></pre></td></tr></table></figure><h2 id="16-只出现一次的数字"><a href="#16-只出现一次的数字" class="headerlink" title="16.只出现一次的数字"></a>16.只出现一次的数字</h2><p>描述：给定一个<strong>非空</strong>整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素</p><p><strong>说明：</strong></p><p>你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗</p><p><strong>解题思路</strong></p><p>首先想到的是利用哈希，但是需要额外空间。然后还有一种是暴力法，两次for循环，找出。最后一种是看了官方题解，采用异或的方法：</p><p>既满足时间复杂度又满足空间复杂度，就要提到位运算中的异或运算 XOR，主要因为异或运算有以下几个特点：</p><ul><li>一个数和 0 做 XOR 运算等于本身：a⊕0 = a</li><li>一个数和其本身做 XOR 运算等于 0：a⊕a = 0</li><li>XOR 运算满足交换律和结合律：a⊕b⊕a = (a⊕a)⊕b = 0⊕b = b</li><li>故而在以上的基础条件上，将所有数字按照顺序做抑或运算，最后剩下的结果即为唯一的数字<br>时间复杂度：O(n)，空间复杂度：O(1)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</span><br><span class="line">            tmp ^= nums[i]</span><br><span class="line">        <span class="keyword">return</span> tmp</span><br></pre></td></tr></table></figure><h2 id="17-设计哈希集合"><a href="#17-设计哈希集合" class="headerlink" title="17.设计哈希集合"></a>17.<a href="https://leetcode-cn.com/problems/design-hashset/" target="_blank" rel="external nofollow noopener noreferrer">设计哈希集合</a></h2><p>描述：不使用任何内建的哈希表库设计一个哈希集合（HashSet）。</p><p>实现 MyHashSet 类：</p><p>void add(key) 向哈希集合中插入值 key 。<br>bool contains(key) 返回哈希集合中是否存在这个值 key 。<br>void remove(key) 将给定值 key 从哈希集合中删除。如果哈希集合中没有这个值，什么也不做。</p><p><strong>说明：</strong></p><p><strong>解题思路</strong></p><p>因为用的python3，所以可以采用集合或者列表来实现。非常简单的一道题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyHashSet</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.map =  set()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, key: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> key <span class="keyword">in</span> self.map:</span><br><span class="line">            self.map.add(key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove</span><span class="params">(self, key: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.map:</span><br><span class="line">            self.map.discard(key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">contains</span><span class="params">(self, key: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Returns true if this set contains the specified element</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.map:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="18-只出现一次的数字-II"><a href="#18-只出现一次的数字-II" class="headerlink" title="18.只出现一次的数字 II"></a>18.<a href="https://leetcode-cn.com/problems/single-number-ii/" target="_blank" rel="external nofollow noopener noreferrer">只出现一次的数字 II</a></h2><p>描述：给你一个整数数组 <code>nums</code> ，除某个元素仅出现 <strong>一次</strong> 外，其余每个元素都恰出现 <strong>三次 。</strong>请你找出并返回那个只出现了一次的元素。</p><p>进阶：你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？</p><p><strong>解题思路</strong></p><p>1.利用map 这种方法很简单，不多说</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">         map = &#123;&#125;</span><br><span class="line">         <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">             <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> map:</span><br><span class="line">                 map[i] = <span class="number">0</span></span><br><span class="line">             <span class="keyword">else</span>:</span><br><span class="line">                 map[i] += <span class="number">1</span></span><br><span class="line">         <span class="keyword">for</span> k,v <span class="keyword">in</span> map.items():</span><br><span class="line">             <span class="keyword">if</span> v == <span class="number">0</span>:</span><br><span class="line">                 <span class="keyword">return</span> k</span><br></pre></td></tr></table></figure><p>2.利用指针。先将数组排序。然后判断当前指针的左右数值是否相等，则可以找出只出现一次的数字。注意一下指针的范围以及一种特殊情况就行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">elif</span> nums[<span class="number">0</span>] != nums[<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(nums)<span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] != nums[i<span class="number">-1</span>] <span class="keyword">and</span> nums[i] != nums[i+<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> nums[i]</span><br><span class="line">            <span class="keyword">elif</span> nums[i] != nums[i+<span class="number">1</span>] <span class="keyword">and</span> i+<span class="number">1</span> == len(nums)<span class="number">-1</span>:</span><br><span class="line">                <span class="keyword">return</span> nums[i+<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="19-有效的括号"><a href="#19-有效的括号" class="headerlink" title="19.有效的括号"></a>19.<a href="https://leetcode-cn.com/problems/valid-parentheses/" target="_blank" rel="external nofollow noopener noreferrer">有效的括号</a></h2><p>描述：给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。</p><p>有效字符串需满足：</p><ol><li>左括号必须用相同类型的右括号闭合。</li><li>左括号必须以正确的顺序闭合。</li></ol><p><strong>解题思路</strong></p><p>利用栈后进先出的特点，可以很简单的做出来，不多做赘述。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    kuohao = &#123;</span><br><span class="line">        <span class="string">')'</span>:<span class="string">'('</span>,</span><br><span class="line">        <span class="string">']'</span>:<span class="string">'['</span>,</span><br><span class="line">        <span class="string">'&#125;'</span>:<span class="string">'&#123;'</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValid</span><span class="params">(self, s: str)</span> -&gt; bool:</span></span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">if</span> len(s) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s :</span><br><span class="line">            <span class="keyword">if</span> i == <span class="string">'('</span> <span class="keyword">or</span> i ==<span class="string">'['</span> <span class="keyword">or</span> i == <span class="string">'&#123;'</span>:</span><br><span class="line">                stack.append(i)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> len(stack) == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                left = stack.pop()</span><br><span class="line">                <span class="keyword">if</span> self.kuohao[i] != left:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> len(stack) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="20-整数转罗马数字"><a href="#20-整数转罗马数字" class="headerlink" title="20.整数转罗马数字"></a>20.<a href="https://leetcode-cn.com/problems/integer-to-roman/" target="_blank" rel="external nofollow noopener noreferrer">整数转罗马数字</a></h2><p>描述：</p><p>罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。</p><div class="table-container"><table><thead><tr><th style="text-align:center">字符</th><th style="text-align:center">数值</th></tr></thead><tbody><tr><td style="text-align:center">I</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">V</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">X</td><td style="text-align:center">10</td></tr><tr><td style="text-align:center">L</td><td style="text-align:center">50</td></tr><tr><td style="text-align:center">C</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">D</td><td style="text-align:center">500</td></tr><tr><td style="text-align:center">M</td><td style="text-align:center">1000</td></tr></tbody></table></div><p>例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做  XXVII, 即为 XX + V + II 。</p><p>通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：</p><p>I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。<br>X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。<br>C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。<br>给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。</p><p><strong>解题思路</strong></p><p>我们用最直白的方法来处理，首先将数字对1000取整，例如2345，对1000取整可以得到2，也就是千位的数字q。然后将原数减去q*1000得到345。再重复这个过程直到个位数处理。只要注意几个特殊罗马数字就行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intToRoman</span><span class="params">(self, num: int)</span> -&gt; str:</span></span><br><span class="line">        res = <span class="string">''</span></span><br><span class="line">        q = num // <span class="number">1000</span></span><br><span class="line">        <span class="keyword">if</span> q &gt; <span class="number">0</span>:</span><br><span class="line">            num -= q * <span class="number">1000</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(q):</span><br><span class="line">                res += <span class="string">'M'</span></span><br><span class="line"></span><br><span class="line">        b = num // <span class="number">100</span></span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">9</span> :</span><br><span class="line">            num -= <span class="number">900</span></span><br><span class="line">            res += <span class="string">'CM'</span></span><br><span class="line">        <span class="keyword">elif</span> b &gt;= <span class="number">5</span>:</span><br><span class="line">            num -= b * <span class="number">100</span></span><br><span class="line">            res += <span class="string">'D'</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(b<span class="number">-5</span>):</span><br><span class="line">                res += <span class="string">'C'</span></span><br><span class="line">        <span class="keyword">elif</span> b == <span class="number">4</span>:</span><br><span class="line">            num -= <span class="number">400</span></span><br><span class="line">            res += <span class="string">'CD'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> b &gt; <span class="number">0</span> :</span><br><span class="line">            num -= b * <span class="number">100</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(b):</span><br><span class="line">                res += <span class="string">'C'</span></span><br><span class="line"></span><br><span class="line">        s = num // <span class="number">10</span></span><br><span class="line">        <span class="keyword">if</span> s == <span class="number">9</span> :</span><br><span class="line">            num -= <span class="number">90</span></span><br><span class="line">            res += <span class="string">'XC'</span></span><br><span class="line">        <span class="keyword">elif</span> s &gt;= <span class="number">5</span>:</span><br><span class="line">            num -= s * <span class="number">10</span></span><br><span class="line">            res += <span class="string">'L'</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(s<span class="number">-5</span>):</span><br><span class="line">                res += <span class="string">'X'</span></span><br><span class="line">        <span class="keyword">elif</span> s == <span class="number">4</span>:</span><br><span class="line">            num -= <span class="number">40</span></span><br><span class="line">            res += <span class="string">'XL'</span></span><br><span class="line">        <span class="keyword">elif</span> s &gt; <span class="number">0</span> :</span><br><span class="line">            num -= s * <span class="number">10</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(s):</span><br><span class="line">                res += <span class="string">'X'</span></span><br><span class="line">        <span class="keyword">if</span> num == <span class="number">9</span>:</span><br><span class="line">            res += <span class="string">'IX'</span></span><br><span class="line">        <span class="keyword">elif</span> num &gt;= <span class="number">5</span>:</span><br><span class="line">            res += <span class="string">'V'</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(num<span class="number">-5</span>):</span><br><span class="line">                res += <span class="string">'I'</span></span><br><span class="line">        <span class="keyword">elif</span> num == <span class="number">4</span>:</span><br><span class="line">                res += <span class="string">'IV'</span></span><br><span class="line">        <span class="keyword">elif</span> num &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(num):</span><br><span class="line">                res += <span class="string">'I'</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h2 id="21-反转链表"><a href="#21-反转链表" class="headerlink" title="21. 反转链表"></a>21. <a href="https://leetcode-cn.com/problems/fan-zhuan-lian-biao-lcof/" target="_blank" rel="external nofollow noopener noreferrer">反转链表</a></h2><p>描述：定义一个函数，输入一个链表的头节点，反转该链表并输出反转后链表的头节点。</p><p>示例:</p><p>输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL<br>输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</p><p><strong>解题思路</strong></p><p>题目要求反转列表，所以用头插法，只需要遍历一遍原列表，则可以完成要求。所谓头插法，就是新建一个空的头结点H，然后遍历原链表，每次遍历新生成一个临时节点temp，将遍历中的结点值赋给temp，再将temp的next指向h，再把h指向temp，这样构造出来的链表就是原链表的逆向。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseList</span><span class="params">(self, head: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        h = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> head <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            temp = ListNode()</span><br><span class="line">            temp.val = head.val</span><br><span class="line">            temp.next = h</span><br><span class="line">            h = temp</span><br><span class="line">            head = head.next</span><br><span class="line">        <span class="keyword">return</span> h</span><br></pre></td></tr></table></figure><p>C语言版本</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     struct ListNode *next;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">struct ListNode* <span class="title">reverseList</span><span class="params">(struct ListNode* head)</span></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>* <span class="title">L</span> = (<span class="title">struct</span> <span class="title">ListNode</span>*)<span class="title">malloc</span>(<span class="title">sizeof</span>(<span class="title">struct</span> <span class="title">ListNode</span>));</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>* <span class="title">node</span>;</span></span><br><span class="line">    L-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">while</span>(head != <span class="literal">NULL</span>)&#123;</span><br><span class="line">        node = (struct ListNode*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(struct ListNode));</span><br><span class="line">        node-&gt;val = head-&gt;val;</span><br><span class="line">        node-&gt;next = L-&gt;next;</span><br><span class="line">        L-&gt;next = node;</span><br><span class="line">        head = head-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> L-&gt;next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="22-罗马数字转整数"><a href="#22-罗马数字转整数" class="headerlink" title="22.罗马数字转整数"></a>22.<a href="https://leetcode-cn.com/problems/roman-to-integer/" target="_blank" rel="external nofollow noopener noreferrer">罗马数字转整数</a></h2><p>描述: 给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。</p><p> 可以参考20题的描述.</p><p><strong>解题思路</strong><br>对于罗马数字转整数，本质就是加法和减法。通过特例可以发现，当左边数字a比右边数字b小的时候，做减法也就是b-a,其余情况都是加法且<strong>最后一位一定是加法</strong>。所以只需遍历字符串，且用当前指针与下一位作比较，若做减法则指针+2,否则右移一位直至遍历结束.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    map = &#123;</span><br><span class="line">        <span class="string">"I"</span>:<span class="number">1</span>,<span class="string">"V"</span>:<span class="number">5</span>,<span class="string">"X"</span>:<span class="number">10</span>,<span class="string">"L"</span>:<span class="number">50</span>,<span class="string">"C"</span>:<span class="number">100</span>,<span class="string">"D"</span>:<span class="number">500</span>,<span class="string">"M"</span>:<span class="number">1000</span>,<span class="string">"IX"</span>:<span class="number">9</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">romanToInt</span><span class="params">(self, s: str)</span> -&gt; int:</span></span><br><span class="line">        res = i = <span class="number">0</span></span><br><span class="line">        l = len(s)</span><br><span class="line">        <span class="keyword">while</span> i + <span class="number">1</span> &lt; l:</span><br><span class="line">            <span class="keyword">if</span> self.map[s[i]] &lt; self.map[s[i+<span class="number">1</span>]]:</span><br><span class="line">                res -= self.map[s[i]]</span><br><span class="line">                res += self.map[s[i+<span class="number">1</span>]]</span><br><span class="line">                i += <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res += self.map[s[i]]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">if</span> i == l - <span class="number">1</span>:</span><br><span class="line">            res += self.map[s[l<span class="number">-1</span>]]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h2 id="23-2的幂"><a href="#23-2的幂" class="headerlink" title="23. 2的幂"></a>23.<a href="https://leetcode-cn.com/problems/power-of-two/" target="_blank" rel="external nofollow noopener noreferrer"> 2的幂</a></h2><p>描述：给定一个整数，编写一个函数来判断它是否是 2 的幂次方。</p><p><strong>解题思路</strong></p><p>最暴力简单的思路，显然，能被2整除到1的数字一定是 2 的幂次方，故一直除2，直到等于1返回true，若小于1则False</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isPowerOfTwo</span><span class="params">(self, n: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> n &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> self.isPowerOfTwo(n/<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="24-添加与搜索单词-数据结构设计"><a href="#24-添加与搜索单词-数据结构设计" class="headerlink" title="24.添加与搜索单词 - 数据结构设计"></a>24.<a href="https://leetcode-cn.com/problems/design-add-and-search-words-data-structure/" target="_blank" rel="external nofollow noopener noreferrer">添加与搜索单词 - 数据结构设计</a></h2><p>描述：请你设计一个数据结构，支持 添加新单词 和 查找字符串是否与任何先前添加的字符串匹配 。</p><p>实现词典类 <code>WordDictionary</code> ：</p><ul><li>WordDictionary() 初始化词典对象</li><li>void addWord(word) 将 word 添加到数据结构中，之后可以对它进行匹配</li><li>bool search(word) 如果数据结构中存在字符串与 word 匹配，则返回 true ；否则，返回  false 。word 中可能包含一些 ‘.’ ，每个 . 都可以表示任何一个字母。</li></ul><p><strong>解题思路</strong></p><ol><li>初始化数组用来保存新单词同时增加一个字典，用来防止重复添加。</li><li>搜索时，先判断搜索词是否在key中，如果有直接返回True，否则进行遍历。</li><li>对于map中的每个单词，若长度与搜索词的长度不同，则直接返回False。否则进行逐个判断，若相等或搜索词中包含’.’，则i++</li><li>若i最终与搜索词长度相等，说明搜索成功并将该搜索词添加到key中，否则搜索失败！</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordDictionary</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.map = []</span><br><span class="line">        self.key = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addWord</span><span class="params">(self, word: str)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.key:</span><br><span class="line">            self.map.append(word)</span><br><span class="line">            self.key[word] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, word: str)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> self.key:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        length = len(word)</span><br><span class="line">        <span class="keyword">for</span> val <span class="keyword">in</span> self.map:</span><br><span class="line">            <span class="keyword">if</span> length != len(val):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; length:</span><br><span class="line">                <span class="keyword">if</span> word[i] == val[i] <span class="keyword">or</span> word[i] == <span class="string">'.'</span>:</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> i == length:</span><br><span class="line">                self.key[word] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="25-相同的树"><a href="#25-相同的树" class="headerlink" title="25.相同的树"></a>25.<a href="https://leetcode-cn.com/problems/same-tree/" target="_blank" rel="external nofollow noopener noreferrer">相同的树</a></h2><p>描述：给你两棵二叉树的根节点 <code>p</code> 和 <code>q</code> ，编写一个函数来检验这两棵树是否相同。如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。</p><p><strong>解题思路</strong></p><p>这是一道简单题，判断两棵树是否相同，可以直接用DFS实现。首先当p，q值不等时，一定不是两颗相同的树，或者其中一颗树为Null，另一棵树不为null，说明两棵树也不想等。只有当两棵树同时为null的时候，它们一定相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSameTree</span><span class="params">(self, p: TreeNode, q: TreeNode)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> p <span class="keyword">and</span> <span class="keyword">not</span> q:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> p <span class="keyword">or</span> <span class="keyword">not</span> q:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">elif</span> p.val != q.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.isSameTree(p.left,q.left) <span class="keyword">and</span> self.isSameTree(p.right,q.right)</span><br></pre></td></tr></table></figure><h2 id="26-二叉树的最大深度"><a href="#26-二叉树的最大深度" class="headerlink" title="26.二叉树的最大深度"></a>26.<a href="https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/" target="_blank" rel="external nofollow noopener noreferrer">二叉树的最大深度</a></h2><p>描述：给定一个二叉树，找出其最大深度。二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。</p><p><strong>解题思路</strong></p><p>对于求深度问题，可以从DFS或者BFS来入手。对于DFS来说，若根结点为空，则直接返回0，否则直接递归左右子树，若左子树高度大于右子树，就返回左子树高度+1，否则返回右子树高度+1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span><span class="params">(self, root: TreeNode)</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        lhigh = self.maxDepth(root.left)</span><br><span class="line">        rhigh = self.maxDepth(root.right)</span><br><span class="line">        <span class="keyword">if</span> (lhigh &gt; rhigh):</span><br><span class="line">            <span class="keyword">return</span> lhigh + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> rhigh + <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="27-二叉树的中序遍历"><a href="#27-二叉树的中序遍历" class="headerlink" title="27.二叉树的中序遍历"></a>27.<a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="external nofollow noopener noreferrer">二叉树的中序遍历</a></h2><p>描述：给定一个二叉树的根节点 <code>root</code> ，返回它的 <strong>中序</strong> 遍历。</p><p><strong>解题思路</strong></p><p>很简单，只需要递归遍历即可，喜欢的使用迭代也行。对于中序来说，显然是LNR，所以先遍历左子树，为空的时候返回，同时加入结点值，然后遍历右子树</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorder</span><span class="params">(self,root,res)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.inorder(root.left,res)</span><br><span class="line">        res.append(root.val)</span><br><span class="line">        self.inorder(root.right,res)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span><span class="params">(self, root: TreeNode)</span> -&gt; List[int]:</span></span><br><span class="line">        res = []</span><br><span class="line">        self.inorder(root,res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h2 id="28-两数相加"><a href="#28-两数相加" class="headerlink" title="28.两数相加"></a>28.<a href="https://leetcode-cn.com/problems/add-two-numbers/" target="_blank" rel="external nofollow noopener noreferrer">两数相加</a></h2><p>描述：给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。</p><p>请你将两个数相加，并以相同形式返回一个表示和的链表。</p><p>你可以假设除了数字 0 之外，这两个数都不会以 0 开头。</p><p><strong>解题思路</strong></p><p>首先，更改一下常规加法的思维惯性。对于该题加法，我们默认从左向右加，并且向右进位。例如243+564，2+5=7， 4+6=10向右进1，则3+4+1=8，即243+564=708<br>故，对于两个链表非空时遍历，初始进位标志c=0：</p><ol><li>l1，l2非空，直接两个链表值和c相加，同时指针后移，并判断是否需要进位，若有进位需将c置为1</li><li>若l1,或l2为空，则将值置为0，重复1步骤的过程</li><li>循环结束后，由于末尾也有可能进位，所以最后需要对c校验，若为1，则需将该值加入到链表尾部。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line"># class ListNode:</span><br><span class="line">#     def __init__(self, val&#x3D;0, next&#x3D;None):</span><br><span class="line">#         self.val &#x3D; val</span><br><span class="line">#         self.next &#x3D; next</span><br><span class="line">class Solution:</span><br><span class="line">    def addTwoNumbers(self, l1: ListNode, l2: ListNode) -&gt; ListNode:</span><br><span class="line">        a &#x3D; b &#x3D; c &#x3D; 0</span><br><span class="line">        p &#x3D; head &#x3D; ListNode()</span><br><span class="line">        while l1 or l2:</span><br><span class="line">            node &#x3D; ListNode()</span><br><span class="line">            if l1:</span><br><span class="line">                a &#x3D; l1.val</span><br><span class="line">                l1 &#x3D; l1.next</span><br><span class="line">            else:</span><br><span class="line">                a &#x3D; 0</span><br><span class="line">            if l2 :</span><br><span class="line">                b &#x3D; l2.val</span><br><span class="line">                l2 &#x3D; l2.next</span><br><span class="line">            else:</span><br><span class="line">                b &#x3D; 0</span><br><span class="line">            if a + b + c &gt; 9:</span><br><span class="line">                node.val &#x3D; a + b + c - 10</span><br><span class="line">                c &#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                node.val &#x3D; a + b + c</span><br><span class="line">                c &#x3D; 0  </span><br><span class="line">                </span><br><span class="line">            p.next &#x3D; node</span><br><span class="line">            p &#x3D; node</span><br><span class="line">        if c &#x3D;&#x3D; 1:</span><br><span class="line">            p.next &#x3D; ListNode(1)</span><br><span class="line">        </span><br><span class="line">        return head.next</span><br><span class="line">。</span><br></pre></td></tr></table></figure><h2 id="29-4的幂"><a href="#29-4的幂" class="headerlink" title="29.4的幂"></a>29.<a href="https://leetcode-cn.com/problems/power-of-four/" target="_blank" rel="external nofollow noopener noreferrer">4的幂</a></h2><p>描述：给定一个整数，写一个函数来判断它是否是 4 的幂次方。如果是，返回 true ；否则，返回 false 。</p><p>整数 n 是 4 的幂次方需满足：存在整数 x 使得 n == 4x</p><p><strong>解题思路</strong></p><p>判断是不是4的幂，只要判断这个数是否能被4一直除到1即可：</p><ol><li>整除到1，返回true</li><li>小于1，返回false</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isPowerOfFour</span><span class="params">(self, n: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> n &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.isPowerOfFour(n/<span class="number">4</span>)</span><br></pre></td></tr></table></figure><h2 id="30-山脉数组的峰顶索引"><a href="#30-山脉数组的峰顶索引" class="headerlink" title="30. 山脉数组的峰顶索引"></a>30. <a href="https://leetcode-cn.com/problems/peak-index-in-a-mountain-array/" target="_blank" rel="external nofollow noopener noreferrer">山脉数组的峰顶索引</a></h2><p>描述：符合下列属性的数组 arr 称为 山脉数组 ：<br>arr.length &gt;= 3<br>存在 i（0 &lt; i &lt; arr.length - 1）使得：<br>arr[0] &lt; arr[1] &lt; … arr[i-1] &lt; arr[i]<br>arr[i] &gt; arr[i+1] &gt; … &gt; arr[arr.length - 1]<br>给你由整数组成的山脉数组 arr ，返回任何满足 arr[0] &lt; arr[1] &lt; … arr[i - 1] &lt; arr[i] &gt; arr[i + 1] &gt; … &gt; arr[arr.length - 1] 的下标 i 。</p><p><strong>解题思路</strong></p><p>按照要求，最简单的方法是遍历，当找到满足arr[i] &lt; arr[i+1] &gt; arr[i+2]就可以了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">peakIndexInMountainArray</span><span class="params">(self, arr: List[int])</span> -&gt; int:</span></span><br><span class="line">        length = len(arr)</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; length - <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">if</span> arr[i] &lt; arr[i+<span class="number">1</span>] <span class="keyword">and</span> arr[i+<span class="number">1</span>] &gt; arr[i+<span class="number">2</span>]:</span><br><span class="line">                <span class="keyword">return</span> i+<span class="number">1</span></span><br><span class="line">            i += <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 回溯 </tag>
            
            <tag> 深度遍历 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NexT升级过程中遇到的坑</title>
      <link href="/posts/cbb37015.html"/>
      <url>/posts/cbb37015.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="NexT从5-1-x-—-gt-7-8-0-中遇到的坑"><a href="#NexT从5-1-x-—-gt-7-8-0-中遇到的坑" class="headerlink" title="NexT从5.1.x  —&gt; 7.8.0 中遇到的坑"></a>NexT从5.1.x  —&gt; 7.8.0 中遇到的坑</h1><blockquote><p>今天闲来无事，发现NexT已经更新到7.8.0，而自己前几天刚刚搭好的博客还是5.1版本，内心十万只羊驼呼啸而过。。。虽然很不情愿，但本着早生晚生都要生的态度，就决定在折腾一把，进行升级。。。谨以此文，纪念我升级过程中遇到的大坑。</p></blockquote><a id="more"></a><p>升级过程其实很简单，直接从github上clone下来就行了，<a href="git clone https://github.com/theme-next/hexo-theme-next themes/">具体可以参考官方文档</a>，这里不过多阐述。直接说遇到的坑吧！</p><ul><li><h2 id="显示的字体变成梵文？？"><a href="#显示的字体变成梵文？？" class="headerlink" title="显示的字体变成梵文？？"></a>显示的字体变成梵文？？</h2><p>其实这个问题是因为没有好好看官方文档导致的。。在5.1版本中，中文设置是叫zh-Hans，在新版本中，中文应该设置为 zh-CN 。之后之间刷新就好了，如果没有效果，先clean一下，之后正常显示中文了。</p></li></ul><ul><li><h2 id="给文章添加的阴影效果不见了"><a href="#给文章添加的阴影效果不见了" class="headerlink" title="给文章添加的阴影效果不见了"></a>给文章添加的阴影效果不见了</h2></li></ul><p>在5.1版本中，可以通过修改_custom下的custom.styl来覆盖原有样式，但是在新版本中，目录结构发生了变换，导致这个方法失效了，所以只能通过其他手段实现。然后在<strong>主题配置</strong>文件中，可以找到以下配置：</p><p><img src="https://i.loli.net/2020/04/07/HnJgxFha7VvdBMj.png" alt></p><p>我们将红框圈出来的这一行的注释去掉，然后在 <strong>站点根目录</strong>下的source目录下，新建_data目录，再新建styles.styl。走到这一步，原本以为成功了，将之前代码复制进去，发现还是没有用。。。后来发现是因为样式名已经变了，所以需要重写，下面是添加的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">.use-motion &#123;</span><br><span class="line">if (hexo-config(&#39;motion.transition.post_block&#39;)) &#123;</span><br><span class="line">.post-block &#123;</span><br><span class="line">   opacity: 0;</span><br><span class="line">   margin-top: 60px;</span><br><span class="line">   margin-bottom: 60px;</span><br><span class="line">   padding: 25px;</span><br><span class="line">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class="line">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class="line">&#125;</span><br><span class="line">.pagination, .comments &#123;</span><br><span class="line">opacity: 0;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在执行hexo clean &amp; hexo s ，就可以在本地看到消失的阴影框又出现了。</p><ul><li><h2 id="文章置顶的功能"><a href="#文章置顶的功能" class="headerlink" title="文章置顶的功能"></a>文章置顶的功能</h2></li></ul><p>这个功能其实还好，和5.1版本一样，直接修改 themes*\layout\_macro目录下的post.swig</p><p>定位到 div class=”post-meta” 标签下，插入如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if post.top %&#125;</span><br><span class="line">    &lt;i class&#x3D;&quot;fa fa-thumb-tack&quot;&gt;&lt;&#x2F;i&gt;</span><br><span class="line">    &lt;font color&#x3D;green&gt;置顶&lt;&#x2F;font&gt;</span><br><span class="line">    &lt;span class&#x3D;&quot;post-meta-divider&quot;&gt;|&lt;&#x2F;span&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>然后保存刷新，就可以看到效果了。（首先要安装hexo-generator-index-pin-top插件，以及卸载掉原本的hexo-generator-index插件）</p><ul><li><h2 id="添加文章阅读标记"><a href="#添加文章阅读标记" class="headerlink" title="添加文章阅读标记"></a>添加文章阅读标记</h2></li></ul><p>这个功能其实也和老版本一样，没有改动。在<code>\themes\*\layout\_macro</code>中新建<code>passage-end-tag.swig</code>文件，然后添加以下代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% if not is_index %&#125;</span><br><span class="line">        &lt;div style&#x3D;&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------已经触及底线啦&lt;i class&#x3D;&quot;fa fa-paw&quot;&gt;&lt;&#x2F;i&gt;感谢您的阅读-------------&lt;&#x2F;div&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure><p>接着在统计目录下，修改post.swig,在<code>post-body</code>后，<code>END POST BODY</code>前，添加以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123;% if not is_index %&#125;</span><br><span class="line">    &#123;% include &#39;passage-end-tag.swig&#39; %&#125;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure><p>最后在<strong>主题配置文件</strong>中 ，添加以下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">passage_end_tag:</span><br><span class="line">  enabled: true</span><br></pre></td></tr></table></figure><p>这样可以实现阅读结束标记了==</p><ul><li><h2 id="不蒜子-不显示"><a href="#不蒜子-不显示" class="headerlink" title="不蒜子 不显示"></a>不蒜子 不显示</h2><p>在更新的7.8版本中，有关于不蒜子的设置，将其设置为true后，还是不显示访问人数，在baidu后发现都是说调用api出错，但是经过查看后发现，api并没有错。。。所以在打开开发者模式后才发现，不蒜子的数据是有的，但是样式后面加上了display:none。。。所以该样式并没有显示。然后在themes\your_theme\layout_third-party\statistics目录下打开busuanzi-counter.swig以及themes\your_theme\layout_macro目录下的post.swig,果然发现了该样式，如图:</p><p><img src="https://i.loli.net/2020/04/07/rSPbIfQn1gl3iUC.png"></p></li></ul><p>  <img src="https://i.loli.net/2020/04/07/rv6Xut9LGczRyqY.png" alt></p><p>  然后直接将样式修改为”display: inline-flex;”,重新启动，果然主页数据出来的，但是点进去具体文章页面，还是没有访问统计。。。实在无语，索性在之前添加的自定义样式文件styles.styl中，添加以下代码，强制覆盖CSS样式：</p><p>  <img src="https://i.loli.net/2020/04/07/LIqgQOTmkafZwRY.png" alt></p><p>  然后执行hexo clean &amp; hexo s ，清除一下缓存，就可以看到数据显示咯~终于成功了，属实坑爹。。</p><p>  效果如下图：</p><p>  <img src="https://i.loli.net/2020/04/07/gAcD6nksmPJd4Ty.png" alt></p><p>  <img src="https://i.loli.net/2020/04/07/XLHCYn6mjWx7VE2.png" alt></p><p>  <img src="https://i.loli.net/2020/04/07/hXeKVJCOzQRZWod.png" alt></p><hr><p>目前就遇到这些问题，如果遇到新问题，还是会追加更新的~</p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
          <category> next </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 版本升级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>neural-networks-deep-learning-week4</title>
      <link href="/posts/d78210a7.html"/>
      <url>/posts/d78210a7.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/360.js"></script><script type="text/javascript" src="/js/baidu.js"></script><h1 id="Deep-Learning-深层神经网络"><a href="#Deep-Learning-深层神经网络" class="headerlink" title="[Deep Learning] 深层神经网络"></a>[Deep Learning] 深层神经网络</h1><p>本周目标：</p><ul><li><p>将深层神经网络视为一个接一个的连续块</p></li><li><p>建立和训练深层L层神经网络</p></li><li><p>分析矩阵和向量维数以检查神经网络的实现。</p></li><li><p>了解如何使用缓存将信息从正向传播传递到反向传播。</p></li><li><p>了解超参数在深度学习中的作用</p><a id="more"></a></li></ul><hr><h1 id="块的思想"><a href="#块的思想" class="headerlink" title="块的思想"></a>块的思想</h1><ul><li>对于每层的计算，可以将其视为一个块，如下图</li></ul><p>  <img src="https://i.loli.net/2020/04/06/I8hkFCdOqEYH1bm.jpg" alt></p><p>  对于此图，只需要理解其过程即可，在前向传播过程中，将变量Z1,Z2等等存储起来，然后在反向传播过程中，就可以很方便地使用他们。</p><h1 id="检查矩阵维度"><a href="#检查矩阵维度" class="headerlink" title="检查矩阵维度"></a>检查矩阵维度</h1><ul><li><p>在写代码过程中，检查各个参数的维度，能有效的避免一些奇怪的BUG。用下图举个栗子</p><p><img src="https://i.loli.net/2020/04/06/74IfwvqOrUk5Wb2.png" style="zoom:50%;"></p><p>如图所示，这是一个五层的神经网络，有参数<script type="math/tex">W^{[1]},b^{[1]}...</script>  首先，先确定<script type="math/tex">W^{[1]}</script>的维度，可以看到，第一个隐藏层有三个单元，即 <script type="math/tex">n^{[1]} = 3</script> ,而输入为<script type="math/tex">x_1,x_2</script>，即<script type="math/tex">n^{[0]}=n_x=2</script>,可以看做是一个 <strong>2 x 1</strong>的列向量。又有<script type="math/tex">z^{[1]} = W^{[1]}x + b^{[1]}</script>,先忽略<script type="math/tex">b^{[1]}</script>，我们已经知道<script type="math/tex">z^{[1]}</script>是 <strong>3 x 1</strong> 的列向量，那么根据线性代数的有关知识，可以直接推断出<script type="math/tex">W^{[1]}</script>是 <strong>3 x 2</strong> 的矩阵。<strong>（若有 A矩阵 的维度为 m x k ,B矩阵的维度为 k x n,那么 AB矩阵相乘得到的矩阵C的维度为 m x n）</strong>。那<script type="math/tex">b^{[1]}</script>的矩阵维度为 <strong>3 x 1</strong>。同理，我们可以推断出 <script type="math/tex">W^{[2]}</script>的维度为 <strong>4 x 3</strong>，<script type="math/tex">b^{[2]}</script> 的维度为 <strong>4 x 1</strong> …..</p><p>由此，可以归纳出一个维度公式，即对于第k层中<strong>(k&gt;0）</strong>，有</p><script type="math/tex; mode=display">\begin{array}\\W^{[k]}的维度 = n^{[k]} * n^{[k-1]} \\b^{[k]}的维度 = n^{[k]} * 1\end{array}</script><p>得到每个参数的维度后，就可以很方便的检验运算是否正确咯。</p></li></ul><h1 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h1><ul><li><h2 id="什么是超参数"><a href="#什么是超参数" class="headerlink" title="什么是超参数"></a>什么是超参数</h2><ul><li>在整个NN中，有许多参数，比如<script type="math/tex">W^{[1]},b^{[1]},W^{[2]},b^{[2]}</script>等等，还有一些其他参数，比如<script type="math/tex">学习率\alpha，迭代次数\#iterations,隐藏层数L，隐藏单元个数n^{[l]},激活函数等等</script>。 而这些这参数都会影响到最终的W,b的结果，所以这些参数就被称作超参数。实际上还有很多超参数，具体的会在之后详细谈及。</li></ul></li><li><h2 id="超参数的作用"><a href="#超参数的作用" class="headerlink" title="超参数的作用"></a>超参数的作用</h2><ul><li><p>在深度学习算法中的超参数如何取值是一个以实验为依据的过程，有时候，可能依赖直觉，比如设置<script type="math/tex">\alpha = 0.01</script>,然后实际操作了一下，得到了某个结果，但是对这个结果不满意，于是把<script type="math/tex">\alpha</script>的值增加到0.05。</p><p>大部分情况下，都很难提前知道这些超参数的最优解，所以具体的取值其实是一个基于试验的过程，在过程中发现新的最优解。</p></li></ul></li></ul><h1 id="多层NN反向传播"><a href="#多层NN反向传播" class="headerlink" title="多层NN反向传播"></a>多层NN反向传播</h1><ul><li><p>在这里，我们具体讨论一下，关于多层网络的反向传播算法。对于前向传播，相信大家应该都很熟悉了，这列就不过多陈述了。主要还是反向传播（Back Propagation，简称BP）。在BP中，第一层的输入应该是在<script type="math/tex">da^{[l]}</script>,而输出是<script type="math/tex">dW^{[l]},db^{[l]}</script>。 </p><p>假设一共有L层网络，Y为真实的label，则在第L层，有</p><script type="math/tex; mode=display">\begin{array}\\dZ^{[L]} = A^{[L]} - Y \\dW^{[L]} = \left(\frac{1}{m}\right) dZ^{[L]}  A^{[L-1]T} \\db^{[L]} = \left(\frac{1}{m}\right)dZ^{[L]}\end{array}</script></li></ul><p>  对于接下来的L-1层，有</p><script type="math/tex; mode=display">  \begin{array}  \\  dZ^{[L-1]} = W^{[L]T} dZ^{[L]} * g^{[L]'}(Z^{[L-1]})  \\  dW^{[l-1]} = \left(\frac{1}{m}\right) dZ^{[L-1]} * A^{[L-2]T} \\  db^{[L-1]} = \left(\frac{1}{m}\right)dZ^{[L-1]}  \end{array}</script><p>  这里公式是针对<font color="gree">所有样本</font>而言，且认为是做二元分类，即最后的<font color="gree">激活函数为sigmoid</font>。 <font color="gree">*</font>  代表 对应元素相乘，即A矩阵为 m x n, B矩阵为 m x n ，那么A * B 依旧是 m x n的矩阵。有了对应的梯度，我们就可以利用for循环来实现对L层网络的反向传播，这里要注意第一次梯度下降时要分开。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>neural-networks-deep-learning-week3</title>
      <link href="/posts/49e68504.html"/>
      <url>/posts/49e68504.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="Deep-Learning-浅层神经网络"><a href="#Deep-Learning-浅层神经网络" class="headerlink" title="[Deep Learning] 浅层神经网络"></a>[Deep Learning] 浅层神经网络</h1><ul><li>理解隐藏层和隐藏单元</li><li>能够使用多种类型的激活函数</li><li>用隐藏层建立一个前向传播和反向传播算法</li><li>应用随机初始化</li></ul><a id="more"></a><h2 id="浅层神经网络结构"><a href="#浅层神经网络结构" class="headerlink" title="浅层神经网络结构"></a>浅层神经网络结构</h2><ul><li><h3 id="单样本前向传播"><a href="#单样本前向传播" class="headerlink" title="单样本前向传播"></a>单样本前向传播</h3><p>首先，看一下神经网络的结构图 </p><p><img src="https://i.loli.net/2020/04/08/BVQtXdyYAgEn2pc.png" alt></p></li></ul><p>这是一个两层的神经网络（输入层不算做一层，认为是第0层）。一般用 <strong>X</strong> 代表输入，也可以用 <script type="math/tex">a^{[0]}</script> 表示 （a代  表激活的意思），用<script type="math/tex">a^{[1]}</script>代表第一层即隐藏层，<script type="math/tex">a^{[2]}</script>代表输出层。所以上图中 ，<strong>X</strong> = <script type="math/tex">a^{[0]}</script> <script type="math/tex">\in R^{3}</script> ,<script type="math/tex">a^{[1]} \in R^{4}</script>,<script type="math/tex">a^{[2]}\in R</script> 。 现在来看隐藏层第一个节点即<script type="math/tex">a^{[1]}_{1}</script>的计算，这个计算和逻辑回归一样。首先算出</p><script type="math/tex; mode=display">z^{[1]}_1 = w^{[1]T}_1x + b^{[1]}_1</script><p> 然后计算</p><script type="math/tex; mode=display">a^{[1]}_1 = sigmoid(z^{[1]}_1)</script><p> 其他节点 同理计算，整理一下</p><script type="math/tex; mode=display">z^{[1]}_1 = w^{[1]T}_1x + b^{[1]}_1,a^{[1]}_1 = sigmoid(z^{[1]}_1)</script><script type="math/tex; mode=display">z^{[1]}_2 = w^{[1]T}_2x + b^{[1]}_2,a^{[1]}_2=sigmoid(z^{[1]}_1)</script><script type="math/tex; mode=display">z^{[1]}_3 = w^{[1]T}_3x + b^{[1]}_3,a^{[1]}_3=sigmoid(z^{[1]}_3)</script><script type="math/tex; mode=display">z^{[1]}_4 = w^{[1]T}_4x + b^{[1]}_4,a^{[1]}_4=sigmoid(z^{[1]}_4)</script><ul><li><h3 id="前向传播向量化"><a href="#前向传播向量化" class="headerlink" title="前向传播向量化"></a>前向传播向量化</h3><p>接下来将这几个式子向量化</p></li></ul><script type="math/tex; mode=display">\left[ \begin{matrix}   --w^{[1]T}_1-- \\   --w^{[1]T}_2-- \\   --w^{[1]T}_3-- \\   --w^{[1]T}_4--   \end{matrix}  \right] *\left[\begin{matrix}   x_1 \\   x_2 \\   x_3\end{matrix}\right]   + \left[\begin{matrix}b^{1}_1 \\b^{1}_2 \\b^{1}_3 \\b^{1}_4\end{matrix}\right]=\left[\begin{matrix}w^{[1]T}_1x + b^{[1]}_1 \\w^{[1]T}_2x + b^{[1]}_2 \\w^{[1]T}_3x + b^{[1]}_3 \\w^{[1]T}_4x + b^{[1]}_4 \end{matrix}\right]=\left[\begin{matrix} z^{[1]}_1 \\ z^{[1]}_2 \\ z^{[1]}_3 \\ z^{[1]}_4 \\\end{matrix}\right]</script><p>​      第一个矩阵为4 x 3的矩阵 ,这是因为 <script type="math/tex">w^{1}_l</script>都属于 三维列向量，现在将他们的转置竖直拼  接为新的矩阵，所以维度4x3。简化一下，可以得到下面的公式</p><script type="math/tex; mode=display">z^{[1]} = W^{[1]} x + b^{[1]}</script><script type="math/tex; mode=display">a^{[1]} = sigmoid(z^{[1]})</script><script type="math/tex; mode=display">z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}</script><script type="math/tex; mode=display">a^{[2]} = sigmoid(z^{[2]})</script><p>​      因为 x 可以写作<script type="math/tex">a^{[0]}</script>,所以</p><script type="math/tex; mode=display">z^{[1]} = W^{[1]} a^{[0]} + b^{[1]}</script><p>​      其中，<script type="math/tex">W^{[1]} \in R^{4*3},b\in R^{4*1}, W^{[2]}\in R^{1*4},b^{[2]} \in R</script>,所以最后 <script type="math/tex">a^{[2]}</script> 也是一个实数。</p><p>​     到此，就完成了一个实例的神经网络计算。</p><ul><li><h3 id="多样本前向传播"><a href="#多样本前向传播" class="headerlink" title="多样本前向传播"></a>多样本前向传播</h3></li></ul><p>  接下来 讨论一下对于多个样本的计算：</p><p>  首先解释一下符号的意思， 第<strong>i</strong>个样本第<strong>k</strong>层的节点定义为 <script type="math/tex">a^{[k](i)}</script>。</p><p>  则在计算m个样本的时候，需要像下面这样计算</p><p><strong>for i = 1 to m:</strong></p><script type="math/tex; mode=display">z^{[1](i)} = W^{[1]} x^{(i)} + b^{[1]}</script><script type="math/tex; mode=display">a^{[1](i)} = sigmoid(z^{[1](i)})</script><script type="math/tex; mode=display">z^{[2](i)} = W^{[2]}a^{[1](i)} + b^{[2]}</script><script type="math/tex; mode=display">a^{[2](i)} = sigmoid(z^{[2](i)})</script><ul><li><h3 id="多样本前向传播向量化"><a href="#多样本前向传播向量化" class="headerlink" title="多样本前向传播向量化"></a>多样本前向传播向量化</h3><p>首先将多个x样本水平拼接为<strong>X</strong>，维度为 n x m ，即</p></li></ul><script type="math/tex; mode=display">  X =   \left[  \begin{matrix}  | & |  &  | \\  x^{(1)} & x^{(2)} & x^{(3)} \\  | & |  &  | \\  \end{matrix} \tag{n * m}  \right]</script><p>  则 向量化 如下</p><script type="math/tex; mode=display">  Z^{[1]} =  W^{[1]} X + b^{[1]}</script><script type="math/tex; mode=display">A^{[1]} = sigmoid(Z^{[1]})</script><script type="math/tex; mode=display">  Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}</script><script type="math/tex; mode=display">  A^{[2]} = sigmoid(Z^{[2]})</script><p>  同样的 ，<script type="math/tex">Z^{[1]}</script> ，<script type="math/tex">A^{[1]}</script>都是矩阵。到此就已经全部完成了。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><ul><li><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>目前为止，我们使用的激活函数一直都是sigmoid。它的图像是这样：</p></li></ul><p><img src="https://i.loli.net/2020/03/31/LlMgaBbvCmTZnyr.png" style="zoom:50%;"></p><p>可以看到，当z非常大或者非常小的时候，它斜率也非常小，这样会使梯度下降很慢。所以基本上不会使用这个激活函数。 <font color="red">除非在做二元分类的时候，需要输出值在o-1之间,只有在这个时候会在输出层选择它。需要注意的是，对于隐藏层和输出层来讲，可以选择不同的激活函数。</font></p><ul><li><h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p>一般情况下，tanh函数都要优于sigmoid函数，它的图像如下：</p><p><img src="https://i.loli.net/2020/03/31/hzbAeauWGZRItFM.png" style="zoom:50%;"></p><p>它的公式为：</p></li></ul><script type="math/tex; mode=display">tanh = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}</script><p>其实是sigmoid函数经过变换后得来的。尽管他的表现要比sigmoid函数要好，但是仍旧面临同样的问题，就是当z过大或过小的时候，斜率非常小。所以也不怎么使用它。</p><ul><li><h3 id="ReLU函数（线性修正单元）"><a href="#ReLU函数（线性修正单元）" class="headerlink" title="ReLU函数（线性修正单元）"></a>ReLU函数（线性修正单元）</h3><p>它的公式为 <strong>ReLU = max(0,z)</strong> , 图像长这样：</p><p><img src="https://i.loli.net/2020/03/31/A3i1mjGnDJQ58YV.png" style="zoom:50%;"></p></li></ul><p>所以只要z为正数，那么斜率就一直为1，z为负数时，斜率为0。虽然当z=0时，导数无定义（左导数和右导数不相等），但是在实际编程时，遇到z=0的概率非常非常小，并且也可以通过指定z=0时，导数为0或者1，所以不用纠结这个问题。</p><p>所以一般情况下都用<strong>ReLU</strong>，或者在你不知道使用哪种激活函数时，就选择它。就比如我们在做二元分类的问题时，可以将所有隐藏层的激活函数都设置为<strong>ReLU</strong>，然后将输出层的激活函数设置为<strong>sigmoid</strong>。</p><p>此外 ，ReLU函数还有另一种版本。</p><ul><li><h3 id="Leaky-ReLU（带泄露的ReLU）"><a href="#Leaky-ReLU（带泄露的ReLU）" class="headerlink" title="Leaky ReLU（带泄露的ReLU）"></a>Leaky ReLU（带泄露的ReLU）</h3></li></ul><p>它的公式为 <strong>ReLU = max(0.01z,z)</strong> , 图像长这样：</p><p><img src="https://i.loli.net/2020/03/31/YEVe8Xv9My4WQZ3.png" style="zoom:50%;"></p><p>当z为负数时，它的斜率不在为0，而是一个轻微的倾斜。这种激活函数实际上使用起来和ReLU没什么太大的区别，具体可以看个人爱好，或者在你的模型中，将两种都尝试一下，来试试效果。</p><p>顺带说一句，因为在NN中，有足够多的隐藏单元来使得z为正数，所以在使用ReLU的时候也不用太担心梯度下降的问题。</p><h2 id="激活函数求导"><a href="#激活函数求导" class="headerlink" title="激活函数求导"></a>激活函数求导</h2><ul><li><h3 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h3><p>关于它的求导，可以参考上一篇博客：<a href="https://www.miraclesky.cn/neural-networks-deep-learning-week2.html" target="_blank" rel="noopener">neural-networks-deep-learning-week2</a></p><p>这里就不再赘述。</p></li><li><h3 id="tanh-函数"><a href="#tanh-函数" class="headerlink" title="tanh 函数"></a>tanh 函数</h3><p>首先，有它的公式</p><script type="math/tex; mode=display">g(z) = tanh(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}</script></li></ul><p>  则有</p><script type="math/tex; mode=display">  g^{'}（z） = 1 - (tanh(z))^{2}</script><p>  具体求导过程可以自行求导，不是很难</p><ul><li><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><script type="math/tex; mode=display">g(z) = max(0,z)</script><p>求导非常简单</p><script type="math/tex; mode=display">g^{'}(z) = \left\{ \begin{aligned}1 & &if && z\geq0 \\0 & &if && z<0\end{aligned}\right.</script><p>当z=0时，我们手动设置导数为0或者1（在数学中这是不可以的，==该点不可导==）</p></li></ul><h2 id="神经网络中的梯度下降"><a href="#神经网络中的梯度下降" class="headerlink" title="神经网络中的梯度下降"></a><font color="red">神经网络中的梯度下降</font></h2><p>现在需要讨论 在NN 中如何进行梯度下降，假设目前还是做得二元分类问题且只包含一层隐藏层，那么我们有损失函数的定义如下：</p><script type="math/tex; mode=display">J(w^{[1]},b^{[1]},w^{[2]},b^{[2]}) =\frac{1}{m}\sum_{i=1}^m  L(\hat{y}^\left(i\right),y^\left(i\right)) \\其中 ，n_x=n^{[0]}为特征的个数，n^{[1]}为隐藏单元个数，n^{[2]}为输出单元个数\\w^{[1]}的维度 为 n^{[1]} * n^{[0]}，b^{[1]}是一个n^{[1]}维向量，即n^{[1]}*1 \\w^{[1]}的维度 为 n^{[2]} * n^{[1]}，b^{[2]}是一个n^{[2]}维向量，即n^{[2]}*1</script><ul><li>梯度下降的做法就是用 变量 减去 学习率与对应偏导数的乘积</li></ul><script type="math/tex; mode=display">\begin{array}\\Repeat\{\\dw^{[1]} = \frac{\partial J}{\partial w^{[1]}}, db^{[1]} = \frac{\partial J}{\partial b^{[1]}} …… \\w^{[1]} = w^{[1]} - \alpha * dw^{[1]},b^{[1]} = b^{[1]} - \alpha * db^{[1]},……\\\}\end{array}</script><ul><li><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>具体的过程为（向量化）：</p></li></ul><script type="math/tex; mode=display">\begin{array}dZ^{[2]} = A^{[2]} - Y \\dW^{[2]} = \frac{1}{m}dZ^{[2]} * A^{[1]T} \\db^{[2]} =  \frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\\axis=1为水平方向，keepdims=True防止输出秩为一的矩阵即(n,)这种形式 \\dZ^{[1]} = W^{[2]T}  dZ^{[2]} .* g^{[1]'}(Z^{[1]})              \\dW^{[1]} = \frac{1}{m} dZ^{[1]}X^{T}\\db^{[1]} = \frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)\\\end{array}</script>  <font color="red">（   .* 代表逐个元素相乘  ）</font><p>整个过程就是这样，如果不是很明白，可以去B站搜一搜，有很多推导过程，由于时间所限，这里就不一一推导。</p><h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>在逻辑回归中，将权重参数全部初始化为0这是可以的，但是在NN中这是不行的。我们来看一看这是为什么。</p><p><img src="https://i.loli.net/2020/03/31/FcsIWydzCPEST6k.png" style="zoom:50%;"></p><p>在上图中，有两个输入即<script type="math/tex">n^{[0]} =2</script>, 隐藏层有两个单元即<script type="math/tex">n^{[1]} =2</script>,那么<script type="math/tex">W^{[1]}</script>是一个2x2的矩阵，<script type="math/tex">b^{[1]}</script>是一个2x1的矩阵。而这会导致无论输入是什么，总有<script type="math/tex">a^{[1]}_1 =</script> <script type="math/tex">a^{[1]}_2</script>。当进行反向传播的时候，由于对称问题，会导致 <script type="math/tex">dz^{[1]}_1</script> = <script type="math/tex">dz^{[1]}_2</script></p><p>…… </p><p>因此，如果全部初始化为0的话，所以的隐藏单元实际上都是相同的，无论训练多久，它们始终相同。推广到多个隐藏层，隐藏单元也依旧成立。所以需要随机初始化。</p><hr><p>本周内容相对而言稍微难一点，主要是反向传播中的链式求导，不太熟的可以去看看链式求导法则。最好是要搞懂原理，不然在之后的多层网络中会比较难以理解</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>neural-networks-deep-learning-week2</title>
      <link href="/posts/3ee1b592.html"/>
      <url>/posts/3ee1b592.html</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" src="/js/baidu.js"></script><script type="text/javascript" src="/js/360.js"></script><h1 id="Deep-Learning-将逻辑回归模型作为神经网络"><a href="#Deep-Learning-将逻辑回归模型作为神经网络" class="headerlink" title="[Deep Learning]将逻辑回归模型作为神经网络"></a>[Deep Learning]将逻辑回归模型作为神经网络</h1><p>最近开始学习吴恩达的deeplearning课程，从第二周开始，会开始介绍关于逻辑回归模型的一些简单定义，在这里开始做一些简单的笔记，用以后面的复习。</p><a id="more"></a><ul><li><h4 id="预测输出"><a href="#预测输出" class="headerlink" title="预测输出"></a>预测输出</h4></li></ul><script type="math/tex; mode=display">  \hat{y} = sigmoid(w^{T} + b)</script><script type="math/tex; mode=display">  sigmoid = \frac{1}{1 + e^{-z}}</script><ul><li><h4 id="损失函数（Loss）："><a href="#损失函数（Loss）：" class="headerlink" title="损失函数（Loss）："></a>损失函数（Loss）：</h4><p>对于线性回归中：</p><script type="math/tex; mode=display">L = \left(\dfrac{1}{2}\right) (\hat{y} - y)^{2}</script><p>而在逻辑回归中，损失函数被定义为：</p><script type="math/tex; mode=display">L = -(ylog(\hat{y}) + (1-y)log(1-\hat{y}))</script><p>具体而言，可以这么理解 yhat：</p><p>即在给定x的情况下 y等于1的概率为多少 </p><script type="math/tex; mode=display">\hat{y} = p(y=1|x)</script></li></ul><p>  也就是说 </p><p>  如果 y=1  </p><script type="math/tex; mode=display">  p(y|x) = \hat{y}</script><p>  如果 y=0</p><script type="math/tex; mode=display">  p(y|x) = 1 - \hat{y}</script><p>  将两种情况写在一起 即为  （将y=0 y=1 代入 可以得到与上面相同的公式）</p><script type="math/tex; mode=display">  p(y|x) = \hat{y}^{y}(1 - \hat{y})^{1 - y}</script><p>  又由于log函数为单调增函数，故取对数</p><script type="math/tex; mode=display">  log\left(p(y|x)\right) = ylog(\hat{y}) + (1-y)log(1-\hat{y}) = -L</script><p>  注意这里的负号，因为在逻辑回归中，我们想最大化概率，所以就需要最小化损失函数。</p><ul><li><h4 id="代价函数（COST）"><a href="#代价函数（COST）" class="headerlink" title="代价函数（COST）"></a>代价函数（COST）</h4><p>在m个样本中的代价可以定义为</p><script type="math/tex; mode=display">log(p) = log\prod_{i=1}^m p(y^\left(i\right)|x^\left(i\right)) = \sum_{i=1}^m log\left(p(y^\left(i\right)|x^\left(i\right))\right) = -\sum_{i=1}^m L(\hat{y}^\left(i\right),y^\left(i\right))</script><p>（在统计学中，有一种最大似然估计的方法，即选择使式子最大化的参数。）</p><p>则有 </p><script type="math/tex; mode=display">J(w,b) =\frac{1}{m}\sum_{i=1}^m  L(\hat{y}^\left(i\right),y^\left(i\right))</script><p>因为这里要求最小值，故不需要这个负号(1/m 为缩放系数，只是为了最后的数值能在更好的尺度上，没有其他特殊含义)</p></li></ul><ul><li><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>在逻辑回归中，我们有以下的定义：</p><p><img src="https://i.loli.net/2020/03/28/P8XJSrQYeNp4ozO.png" alt></p><p>对其求偏导数（链式求导，如果不熟悉，可以看宇哥的十八讲~）</p><script type="math/tex; mode=display">\frac{dL}{da} = -\frac{y}{a} + \frac{1-y}{1-a}</script></li></ul><script type="math/tex; mode=display">  \frac{da}{dz} =-(1+e^{-z})^{-2} * -e^{-z} = e^{-z}*(1+e^{-z})^{-2} = a*(1-a)</script><p>注：</p><script type="math/tex; mode=display">e^{-z}*(1+e^{-z})^{-2} = \frac{e^{-z}}{(1+e^{-z})^{2}} = \frac{1+e^{-z}-1}{(1+e^{-z})^{2}} = \frac{1}{1+e^{-z}} - \frac{1}{(1+e^{-z})^{2}} = a-a^2=a(1-a)</script><p>则有</p><script type="math/tex; mode=display">\frac{dL}{dz} = \frac{dL}{da} * \frac{da}{dz} =(-\frac{y}{a} + \frac{1-y}{1-a}) * a(1-a)=a-y</script><p>同样的</p><script type="math/tex; mode=display">\frac{dL}{dw_1} = x_1*dz</script><p>在计算出这些导数后，就可以进行梯度下降了</p><script type="math/tex; mode=display">w_1 = w_1 - \alpha*dw_1</script><script type="math/tex; mode=display">w_2 = w_2 - \alpha*dw_2</script><script type="math/tex; mode=display">b = b -\alpha*db</script><hr><p>以上就是对第二周的小小整理（没有对向量化的部分以及numpy的使用做总结，关于numpy的使用会单独写），具体来说，这门课和之前的机器学习中讲的略有不同，比如记号之类的地方，但是大体而言还是差不多的，加油加油！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
